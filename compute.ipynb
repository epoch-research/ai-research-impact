{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from researcher_impact.plotting import save_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_location = 'results/'\n",
    "os.makedirs(result_file_location, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Largest training runs for leading companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_aliases = {\n",
    "    \"Google\": \"Google\",\n",
    "    \"Google Research\": \"Google\",\n",
    "    \"Google Brain\": \"Google\",\n",
    "    \"Google Inc.\": \"Google\",\n",
    "    \"Google AI, Brain team\": \"Google\",\n",
    "    \"Google Research, Brain Team\": \"Google\",\n",
    "    \"Google AI\": \"Google\",\n",
    "    \"Google Brain,Google Research\": \"Google\",\n",
    "    \"Google Inc\": \"Google\",\n",
    "    \"DeepMind\": \"DeepMind\",\n",
    "    \"Google DeepMind\": \"DeepMind\",\n",
    "    \"Meta AI\": \"Meta\",\n",
    "    \"MetaAI\": \"Meta\",\n",
    "    \"Facebook AI Research\": \"Meta\",\n",
    "    \"Facebook AI research\": \"Meta\",\n",
    "    \"Facebook\": \"Meta\",\n",
    "    \"Facebook AI\": \"Meta\",\n",
    "    \"OpenAI\": \"OpenAI\",\n",
    "    \"Open AI\": \"OpenAI\",\n",
    "    \"Microsoft Research\": \"Microsoft\",\n",
    "    \"Microsoft\": \"Microsoft\",\n",
    "    \"Microsoft Research,Peking University\": \"Microsoft\",\n",
    "    \"Microsoft Bing\": \"Microsoft\",\n",
    "    \"Alibaba Group\": \"Alibaba\",\n",
    "    \"NVIDIA\": \"NVIDIA\",\n",
    "    \"Nvidia\": \"NVIDIA\",\n",
    "    \"Baidu Research- Silicon Valley AI Lab\": \"Baidu\",\n",
    "    \"Baidu\": \"Baidu\",\n",
    "    \"Amazon\": \"Amazon\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort by publication date\n",
    "- Filter companies of interest + rename companies to consistent alias => new DataFrame\n",
    "- Get the maximum envelope of the data => new DataFrame\n",
    "- Add on the last maximum to the current date, so there's a horizontal line continuing until the current date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from the Parameters, Compute and Data Trends in ML sheet\n",
    "sheet_id = '1AAIebjNsnJj_uKALHbXNfn3_YsT6sHXtCU0q7OIPuc4'\n",
    "data_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet='\n",
    "df = pd.read_csv(data_url + 'ALL%20ML%20SYSTEMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = [\"System\", \"Organization\", \"Publication date\", \"Training compute (FLOP)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Organization\", \"Training compute (FLOP)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejected samples\n",
    "# We don't think the full training run was actually done\n",
    "df.drop(df[df[\"System\"] == \"Megatron-LM (1T)\"].index, inplace=True)\n",
    "# Kingma was affiliated with OpenAI on the paper for this system, but only in the 2017 version rather than the original 2014 version\n",
    "df.drop(df[df[\"System\"] == \"ADAM (CIFAR-10)\"].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Publication date'] = pd.to_datetime(df['Publication date'])  # Ensure date column is in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Publication date', inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Theseus</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>6.950000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>1959-02-01</td>\n",
       "      <td>6.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>IBM</td>\n",
       "      <td>1959-07-01</td>\n",
       "      <td>4.280000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADALINE</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>1960-06-30</td>\n",
       "      <td>9.900000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>BLOOM</td>\n",
       "      <td>Hugging Face,BigScience</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>1.800000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>AR-LDM</td>\n",
       "      <td>Alibaba,University of Waterloo,Vector Institute</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>5.100000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>LLaMA (65B)</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>5.500000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2.100000e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Google</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>7.340000e+24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  \\\n",
       "0                   Theseus   \n",
       "1         Perceptron Mark I   \n",
       "2       Pandemonium (morse)   \n",
       "3    Samuel Neural Checkers   \n",
       "4                   ADALINE   \n",
       "..                      ...   \n",
       "176                   BLOOM   \n",
       "177                  AR-LDM   \n",
       "178             LLaMA (65B)   \n",
       "179                   GPT-4   \n",
       "180                  PaLM 2   \n",
       "\n",
       "                                          Organization Publication date  \\\n",
       "0                                    Bell Laboratories       1950-07-02   \n",
       "1    Cornell Aeronautical Laboratory,Cornell Univer...       1957-01-01   \n",
       "2                Massachusetts Institute of Technology       1959-02-01   \n",
       "3                                                  IBM       1959-07-01   \n",
       "4                                  Stanford University       1960-06-30   \n",
       "..                                                 ...              ...   \n",
       "176                            Hugging Face,BigScience       2022-11-08   \n",
       "177    Alibaba,University of Waterloo,Vector Institute       2022-11-20   \n",
       "178                                            Meta AI       2023-02-24   \n",
       "179                                             OpenAI       2023-03-15   \n",
       "180                                             Google       2023-05-10   \n",
       "\n",
       "     Training compute (FLOP)  \n",
       "0               4.000000e+01  \n",
       "1               6.950000e+05  \n",
       "2               6.000000e+08  \n",
       "3               4.280000e+08  \n",
       "4               9.900000e+03  \n",
       "..                       ...  \n",
       "176             1.800000e+23  \n",
       "177             5.100000e+20  \n",
       "178             5.500000e+23  \n",
       "179             2.100000e+25  \n",
       "180             7.340000e+24  \n",
       "\n",
       "[181 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_of_interest]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter companies of interest + rename companies to consistent alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bell Laboratories\n",
      "Cornell Aeronautical Laboratory,Cornell University\n",
      "Massachusetts Institute of Technology\n",
      "IBM\n",
      "Stanford University\n",
      "NHK Broadcasting Science Research Laboratories\n",
      "University of California\n",
      "Princeton University\n",
      "Stanford, CalTech\n",
      "AT&T Bell Laboratories\n",
      "Carnegie Mellon University \n",
      "IBM\n",
      "Indian Statistical Institute\n",
      "Carnegie Mellon University\n",
      "The Technical University of Munich\n",
      "National Chiao Tung University\n",
      "AT&T Labs\n",
      "Mitsubishi Electric Research Labs and Compaq CRL\n",
      "UniversitÃ© de MontrÃ©al\n",
      "IDSIA and TU Munich\n",
      "Stanford\n",
      "IDSIA ; University of Lugano & SUPSI\n",
      "University of Montreal\n",
      "Brno University of Technology, Johns Hopkins University\n",
      "Brno University of Technology,Johns Hopkins University\n",
      "IDSIA\n",
      "University of Toronto\n",
      "University of Toronto\n",
      "University of Toronto\n",
      "Google\n",
      "University of Toronto\n",
      "Universidad Nacional de Cordoba,Xerox Research Centre Europe,Inteligent Systems Lab Amsterdam,University of Amsterdam,LEAR Team,INRIA Grenoble\n",
      "IDSIA\n",
      "Google\n",
      "NYU\n",
      "CNRS,Google\n",
      "DeepMind\n",
      "Univeristy of Amsterdam\n",
      "Universite de MontrÃ©al\n",
      "Microsoft,Xiâ€™an Jiaotong University,University of Science and Technology of China\n",
      "University College London\n",
      "Universite de MontrÃ©al,Jacobs University Bremen\n",
      "University of Oxford\n",
      "Google\n",
      "Microsoft Research\n",
      "Google,University of Michigan,University of North Carolina\n",
      "Google DeepMind\n",
      "Baidu Research- Silicon Valley AI Lab\n",
      "Microsoft\n",
      "DeepMind\n",
      "Microsoft research, Tsinghua university\n",
      "University of Toronto\n",
      "University of Toronto\n",
      "Google\n",
      "Google\n",
      "Google Brain\n",
      "Carnegie Mellon University\n",
      "DeepMind\n",
      "University of Alberta,Charles University,Czech Technical University\n",
      "Jagiellonian University,Google Brain\n",
      "Google Research,Google Brain\n",
      "CMU,Google Research\n",
      "Facebook AI research\n",
      "OpenAI\n",
      "DeepMind\n",
      "Johns Hopkins University,Stanford,Google AI\n",
      "DeepMind\n",
      "Google Brain\n",
      "DeepMind\n",
      "University of Washington\n",
      "Facebook\n",
      "OpenAI\n",
      "DeepMind\n",
      "Heriot-Watt University,DeepMind\n",
      "Google\n",
      "University of Freiburg\n",
      "DeepMind,University of Oxford,Carnegie Mellon University,Google Brain\n",
      "OpenAI\n",
      "MIT\n",
      "Jane Street\n",
      "Tel Aviv University, MIT\n",
      "Google\n",
      "Google\n",
      "DeepMind\n",
      "Facebook AI\n",
      "Facebook\n",
      "Facebook AI Research\n",
      "MIT\n",
      "NVIDIA\n",
      "NVIDIA\n",
      "OpenAI\n",
      "Brown and Facebook AI Research\n",
      "HuggingFace\n",
      "Open AI\n",
      "Google\n",
      "Google\n",
      "DeepMind\n",
      "Carnegie Mellon University,Google\n",
      "DeepMind\n",
      "OpenAI\n",
      "OpenAI\n",
      "DeepMind\n",
      "Google Brain\n",
      "Toyota Technological Institute at Chicago,Google\n",
      "Microsoft\n",
      "Salesforce research,Stanford\n",
      "Stanford University, Google Brain\n",
      "MIT-IBM Watson AI Lab\n",
      "OpenAI\n",
      "Open AI\n",
      "Open AI\n",
      "Google\n",
      "Google\n",
      "Facebook AI \n",
      "Google Brain\n",
      "Facebook\n",
      "Tsinghua University, Princeton, Mila- Quebec AI, University de Montreal, HEC, CIFAR\n",
      "Tsinghua University, BAAI\n",
      "American University of Beirut\n",
      "OpenAI\n",
      "Open AI\n",
      "BAAI\n",
      "Google\n",
      "Google Brain\n",
      "BAAI\n",
      "BAAI\n",
      "Alibaba Group\n",
      "EleutherAI\n",
      "Alibaba Group\n",
      "Huawei Noah's Ark Lab\n",
      "Technical University of Munich,Med AI Technology,NVIDIA,Oak Ridge National Laboratory,Google\n",
      "Google Cloud,Google Research\n",
      "Tsinghua University, DAMO academy Alibaba\n",
      "Google Brain\n",
      "Microsoft\n",
      "Google Research\n",
      "UC Berkeley\n",
      "Google\n",
      "Baidu Inc.\n",
      "Facebook AI Research\n",
      "DeepMind\n",
      "Facebook AI Research,Inria\n",
      "AI21 Labs\n",
      "Google Research\n",
      "NAVER,Search Solutions, Inc.\n",
      "Facebook\n",
      "Alibaba\n",
      "Microsoft,NVIDIA\n",
      "Inspur\n",
      "Hugging Face,Brown University,BigScience\n",
      "LightOn,LPENS,INRIA\n",
      "Inspur\n",
      "Microsoft Research,Peking University\n",
      "DeepMind\n",
      "Baidu\n",
      "Google Brain\n",
      "DeepMind\n",
      "EleutherAI\n",
      "Google\n",
      "DeepMind\n",
      "Google Research\n",
      "Stability AI, Runway\n",
      "MetaAI\n",
      "Meta AI\n",
      "NVIDIA,UC Berkeley\n",
      "DeepMind\n",
      "Google\n",
      "Google Research\n",
      "Yandex\n",
      "AI Sweden,RISE\n",
      "Google\n",
      "Meta AI\n",
      "Amazon\n",
      "Tsinghua KEG\n",
      "OpenAI\n",
      "IDEA CCNL\n",
      "Hugging Face,BigScience\n",
      "Alibaba,University of Waterloo,Vector Institute\n",
      "Meta AI\n",
      "OpenAI\n",
      "Google\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Unsupervised High-level Feature Learner</td>\n",
       "      <td>Google</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>6.000000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Word2Vec (large)</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-10-16</td>\n",
       "      <td>3.890000e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TransE</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>1.340000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DQN</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>2.300000e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SPPNet</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>3.410000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>AlexaTM 20B</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>2.040000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Whisper</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>4.650000e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>LLaMA (65B)</td>\n",
       "      <td>Meta</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>5.500000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2.100000e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Google</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>7.340000e+24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      System Organization Publication date  \\\n",
       "29   Unsupervised High-level Feature Learner       Google       2012-07-12   \n",
       "33                          Word2Vec (large)       Google       2013-10-16   \n",
       "35                                    TransE       Google       2013-12-05   \n",
       "36                                       DQN     DeepMind       2013-12-19   \n",
       "39                                    SPPNet    Microsoft       2014-06-18   \n",
       "..                                       ...          ...              ...   \n",
       "172                              AlexaTM 20B       Amazon       2022-08-02   \n",
       "174                                  Whisper       OpenAI       2022-09-21   \n",
       "178                              LLaMA (65B)         Meta       2023-02-24   \n",
       "179                                    GPT-4       OpenAI       2023-03-15   \n",
       "180                                   PaLM 2       Google       2023-05-10   \n",
       "\n",
       "     Training compute (FLOP)  \n",
       "29              6.000000e+17  \n",
       "33              3.890000e+16  \n",
       "35              1.340000e+18  \n",
       "36              2.300000e+15  \n",
       "39              3.410000e+18  \n",
       "..                       ...  \n",
       "172             2.040000e+23  \n",
       "174             4.650000e+22  \n",
       "178             5.500000e+23  \n",
       "179             2.100000e+25  \n",
       "180             7.340000e+24  \n",
       "\n",
       "[106 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for i, row in df.iterrows():\n",
    "    orgs = row[\"Organization\"]\n",
    "    print(orgs)\n",
    "    org_list = [org.strip() for org in orgs.split(\",\")]\n",
    "    for org in org_list:\n",
    "        if org in company_aliases.keys():\n",
    "            alias = company_aliases[org]\n",
    "            new_row = row.copy()\n",
    "            new_row[\"Organization\"] = alias\n",
    "            rows.append(new_row)\n",
    "\n",
    "company_df = pd.DataFrame(rows)\n",
    "company_df[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_max_compute_df = company_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Unsupervised High-level Feature Learner</td>\n",
       "      <td>Google</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>6.000000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Word2Vec (large)</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-10-16</td>\n",
       "      <td>6.000000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TransE</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>1.340000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DQN</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>2.300000e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SPPNet</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>3.410000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>AlexaTM 20B</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>2.040000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Whisper</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>3.140000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>LLaMA (65B)</td>\n",
       "      <td>Meta</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>5.500000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2.100000e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Google</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>7.340000e+24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      System Organization Publication date  \\\n",
       "29   Unsupervised High-level Feature Learner       Google       2012-07-12   \n",
       "33                          Word2Vec (large)       Google       2013-10-16   \n",
       "35                                    TransE       Google       2013-12-05   \n",
       "36                                       DQN     DeepMind       2013-12-19   \n",
       "39                                    SPPNet    Microsoft       2014-06-18   \n",
       "..                                       ...          ...              ...   \n",
       "172                              AlexaTM 20B       Amazon       2022-08-02   \n",
       "174                                  Whisper       OpenAI       2022-09-21   \n",
       "178                              LLaMA (65B)         Meta       2023-02-24   \n",
       "179                                    GPT-4       OpenAI       2023-03-15   \n",
       "180                                   PaLM 2       Google       2023-05-10   \n",
       "\n",
       "     Training compute (FLOP)  \n",
       "29              6.000000e+17  \n",
       "33              6.000000e+17  \n",
       "35              1.340000e+18  \n",
       "36              2.300000e+15  \n",
       "39              3.410000e+18  \n",
       "..                       ...  \n",
       "172             2.040000e+23  \n",
       "174             3.140000e+23  \n",
       "178             5.500000e+23  \n",
       "179             2.100000e+25  \n",
       "180             7.340000e+24  \n",
       "\n",
       "[106 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_max_compute_df[\"Training compute (FLOP)\"] = company_df.groupby(\"Organization\")['Training compute (FLOP)'].cummax()\n",
    "company_max_compute_df[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alibaba 3.6e+22\n",
      "Amazon 2.04e+23\n",
      "Baidu 3.14e+23\n",
      "DeepMind 6.31e+23\n",
      "Google 7.34e+24\n",
      "Meta 5.5e+23\n",
      "Microsoft 1.17e+24\n",
      "NVIDIA 1.17e+24\n",
      "OpenAI 2.1e+25\n"
     ]
    }
   ],
   "source": [
    "rows_to_add = []\n",
    "for org, group_data in company_max_compute_df.groupby(\"Organization\"):\n",
    "    print(org, group_data[\"Training compute (FLOP)\"].max())\n",
    "    current_date = datetime.now().date()  # Get the current date\n",
    "    compute = group_data[\"Training compute (FLOP)\"].max()\n",
    "    # Create a new row with NaN for all columns except \"Organization\", \"Publication date\", and \"Training compute (FLOP)\"\n",
    "    new_row = pd.Series(\n",
    "        {\n",
    "            \"Organization\": org,\n",
    "            \"Publication date\": current_date,\n",
    "            \"Training compute (FLOP)\": compute,\n",
    "        }\n",
    "    )\n",
    "    rows_to_add.append(new_row)\n",
    "\n",
    "# Create a DataFrame from the rows to be added\n",
    "new_data = pd.DataFrame(rows_to_add)\n",
    "\n",
    "# Concatenate the new_data DataFrame to the original filtered_df\n",
    "company_max_compute_df = pd.concat([company_max_compute_df, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization Categorization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time notes</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Training compute cost (2020 USD)</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Self-supervised training</th>\n",
       "      <th>Compute Sponsor Categorization</th>\n",
       "      <th>Epistemic status</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376.0</td>\n",
       "      <td>Unsupervised High-level Feature Learner</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Quoc V. Le, Marc'Aurelio Ranzato, Rajat Monga,...</td>\n",
       "      <td>2012-07-12 00:00:00</td>\n",
       "      <td>Building High-level Features Using Large Scale...</td>\n",
       "      <td>https://arxiv.org/pdf/1112.6209.pdf</td>\n",
       "      <td>...</td>\n",
       "      <td>\"We train this network using model parallelism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unsupervised</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardware not reported</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Likely</td>\n",
       "      <td>We consider the problem of building high-level...</td>\n",
       "      <td>2023-06-15 15:50:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>362.0</td>\n",
       "      <td>Word2Vec (large)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Semantic embedding</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>T Mikolov, I Sutskever, K Chen, GS Corrado</td>\n",
       "      <td>2013-10-16 00:00:00</td>\n",
       "      <td>Distributed Representations of Words and Phras...</td>\n",
       "      <td>https://arxiv.org/abs/1310.4546</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-14 14:54:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358.0</td>\n",
       "      <td>TransE</td>\n",
       "      <td>Other</td>\n",
       "      <td>Entity embedding</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry - Academia Collaboration</td>\n",
       "      <td>Antoine Bordes, Nicolas Usunier, Alberto Garci...</td>\n",
       "      <td>2013-12-05 00:00:00</td>\n",
       "      <td>Translating Embeddings for Modeling Multi- rel...</td>\n",
       "      <td>https://papers.nips.cc/paper/2013/hash/1cecc7a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-03 20:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>DQN</td>\n",
       "      <td>Games</td>\n",
       "      <td>Atari</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>Industry</td>\n",
       "      <td>V Mnih, K Kavukcuoglu, D Silver, A Graves</td>\n",
       "      <td>2013-12-19 00:00:00</td>\n",
       "      <td>Playing Atari with Deep Reinforcement Learning</td>\n",
       "      <td>https://arxiv.org/abs/1312.5602</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-14 14:57:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>344.0</td>\n",
       "      <td>SPPNet</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Industry - Academia Collaboration</td>\n",
       "      <td>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</td>\n",
       "      <td>2014-06-18 00:00:00</td>\n",
       "      <td>Spatial Pyramid Pooling in Deep Convolutional ...</td>\n",
       "      <td>https://arxiv.org/abs/1406.4729</td>\n",
       "      <td>...</td>\n",
       "      <td>\"All networks in this paper can be trained on ...</td>\n",
       "      <td>NVIDIA GeForce GTX TITAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-01 10:30:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Google</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                   System    Domain  \\\n",
       "0    376.0  Unsupervised High-level Feature Learner    Vision   \n",
       "1    362.0                         Word2Vec (large)  Language   \n",
       "2    358.0                                   TransE     Other   \n",
       "3    355.0                                      DQN     Games   \n",
       "4    344.0                                   SPPNet    Vision   \n",
       "..     ...                                      ...       ...   \n",
       "110    NaN                                      NaN       NaN   \n",
       "111    NaN                                      NaN       NaN   \n",
       "112    NaN                                      NaN       NaN   \n",
       "113    NaN                                      NaN       NaN   \n",
       "114    NaN                                      NaN       NaN   \n",
       "\n",
       "                     Task Organization        Organization Categorization  \\\n",
       "0    Image classification       Google                           Industry   \n",
       "1      Semantic embedding       Google                           Industry   \n",
       "2        Entity embedding       Google  Industry - Academia Collaboration   \n",
       "3                   Atari     DeepMind                           Industry   \n",
       "4    Image classification    Microsoft  Industry - Academia Collaboration   \n",
       "..                    ...          ...                                ...   \n",
       "110                   NaN       Google                                NaN   \n",
       "111                   NaN         Meta                                NaN   \n",
       "112                   NaN    Microsoft                                NaN   \n",
       "113                   NaN       NVIDIA                                NaN   \n",
       "114                   NaN       OpenAI                                NaN   \n",
       "\n",
       "                                               Authors     Publication date  \\\n",
       "0    Quoc V. Le, Marc'Aurelio Ranzato, Rajat Monga,...  2012-07-12 00:00:00   \n",
       "1           T Mikolov, I Sutskever, K Chen, GS Corrado  2013-10-16 00:00:00   \n",
       "2    Antoine Bordes, Nicolas Usunier, Alberto Garci...  2013-12-05 00:00:00   \n",
       "3            V Mnih, K Kavukcuoglu, D Silver, A Graves  2013-12-19 00:00:00   \n",
       "4    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun  2014-06-18 00:00:00   \n",
       "..                                                 ...                  ...   \n",
       "110                                                NaN           2023-08-17   \n",
       "111                                                NaN           2023-08-17   \n",
       "112                                                NaN           2023-08-17   \n",
       "113                                                NaN           2023-08-17   \n",
       "114                                                NaN           2023-08-17   \n",
       "\n",
       "                                             Reference  \\\n",
       "0    Building High-level Features Using Large Scale...   \n",
       "1    Distributed Representations of Words and Phras...   \n",
       "2    Translating Embeddings for Modeling Multi- rel...   \n",
       "3       Playing Atari with Deep Reinforcement Learning   \n",
       "4    Spatial Pyramid Pooling in Deep Convolutional ...   \n",
       "..                                                 ...   \n",
       "110                                                NaN   \n",
       "111                                                NaN   \n",
       "112                                                NaN   \n",
       "113                                                NaN   \n",
       "114                                                NaN   \n",
       "\n",
       "                                                  Link  ...  \\\n",
       "0                  https://arxiv.org/pdf/1112.6209.pdf  ...   \n",
       "1                      https://arxiv.org/abs/1310.4546  ...   \n",
       "2    https://papers.nips.cc/paper/2013/hash/1cecc7a...  ...   \n",
       "3                      https://arxiv.org/abs/1312.5602  ...   \n",
       "4                      https://arxiv.org/abs/1406.4729  ...   \n",
       "..                                                 ...  ...   \n",
       "110                                                NaN  ...   \n",
       "111                                                NaN  ...   \n",
       "112                                                NaN  ...   \n",
       "113                                                NaN  ...   \n",
       "114                                                NaN  ...   \n",
       "\n",
       "                                   Training time notes  \\\n",
       "0    \"We train this network using model parallelism...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    \"All networks in this paper can be trained on ...   \n",
       "..                                                 ...   \n",
       "110                                                NaN   \n",
       "111                                                NaN   \n",
       "112                                                NaN   \n",
       "113                                                NaN   \n",
       "114                                                NaN   \n",
       "\n",
       "            Training hardware      Approach  Training compute cost (2020 USD)  \\\n",
       "0                         NaN  Unsupervised                               NaN   \n",
       "1                         NaN           NaN                              0.55   \n",
       "2                         NaN           NaN                             17.58   \n",
       "3                         NaN           NaN                              0.04   \n",
       "4    NVIDIA GeForce GTX TITAN           NaN                             65.07   \n",
       "..                        ...           ...                               ...   \n",
       "110                       NaN           NaN                               NaN   \n",
       "111                       NaN           NaN                               NaN   \n",
       "112                       NaN           NaN                               NaN   \n",
       "113                       NaN           NaN                               NaN   \n",
       "114                       NaN           NaN                               NaN   \n",
       "\n",
       "        Compute cost notes  Self-supervised training  \\\n",
       "0    Hardware not reported                       NaN   \n",
       "1                      NaN                       NaN   \n",
       "2                      NaN                       NaN   \n",
       "3                      NaN                       NaN   \n",
       "4                      NaN                       NaN   \n",
       "..                     ...                       ...   \n",
       "110                    NaN                       NaN   \n",
       "111                    NaN                       NaN   \n",
       "112                    NaN                       NaN   \n",
       "113                    NaN                       NaN   \n",
       "114                    NaN                       NaN   \n",
       "\n",
       "    Compute Sponsor Categorization Epistemic status  \\\n",
       "0                         Industry           Likely   \n",
       "1                         Industry              NaN   \n",
       "2                         Industry              NaN   \n",
       "3                         Industry              NaN   \n",
       "4                         Industry              NaN   \n",
       "..                             ...              ...   \n",
       "110                            NaN              NaN   \n",
       "111                            NaN              NaN   \n",
       "112                            NaN              NaN   \n",
       "113                            NaN              NaN   \n",
       "114                            NaN              NaN   \n",
       "\n",
       "                                              Abstract        Last Modified  \n",
       "0    We consider the problem of building high-level...  2023-06-15 15:50:10  \n",
       "1                                                  NaN  2023-06-14 14:54:39  \n",
       "2                                                  NaN  2023-08-03 20:32:27  \n",
       "3                                                  NaN  2023-06-14 14:57:17  \n",
       "4                                                  NaN  2023-08-01 10:30:07  \n",
       "..                                                 ...                  ...  \n",
       "110                                                NaN                  NaN  \n",
       "111                                                NaN                  NaN  \n",
       "112                                                NaN                  NaN  \n",
       "113                                                NaN                  NaN  \n",
       "114                                                NaN                  NaN  \n",
       "\n",
       "[115 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_max_compute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsupervised High-level Feature Learner</td>\n",
       "      <td>Google</td>\n",
       "      <td>2012-07-12 00:00:00</td>\n",
       "      <td>6.000000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2Vec (large)</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-10-16 00:00:00</td>\n",
       "      <td>6.000000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TransE</td>\n",
       "      <td>Google</td>\n",
       "      <td>2013-12-05 00:00:00</td>\n",
       "      <td>1.340000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DQN</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2013-12-19 00:00:00</td>\n",
       "      <td>2.300000e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPPNet</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2014-06-18 00:00:00</td>\n",
       "      <td>3.410000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Google</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>7.340000e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Meta</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>5.500000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>1.170000e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>1.170000e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>2.100000e+25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      System Organization  \\\n",
       "0    Unsupervised High-level Feature Learner       Google   \n",
       "1                           Word2Vec (large)       Google   \n",
       "2                                     TransE       Google   \n",
       "3                                        DQN     DeepMind   \n",
       "4                                     SPPNet    Microsoft   \n",
       "..                                       ...          ...   \n",
       "110                                      NaN       Google   \n",
       "111                                      NaN         Meta   \n",
       "112                                      NaN    Microsoft   \n",
       "113                                      NaN       NVIDIA   \n",
       "114                                      NaN       OpenAI   \n",
       "\n",
       "        Publication date  Training compute (FLOP)  \n",
       "0    2012-07-12 00:00:00             6.000000e+17  \n",
       "1    2013-10-16 00:00:00             6.000000e+17  \n",
       "2    2013-12-05 00:00:00             1.340000e+18  \n",
       "3    2013-12-19 00:00:00             2.300000e+15  \n",
       "4    2014-06-18 00:00:00             3.410000e+18  \n",
       "..                   ...                      ...  \n",
       "110           2023-08-17             7.340000e+24  \n",
       "111           2023-08-17             5.500000e+23  \n",
       "112           2023-08-17             1.170000e+24  \n",
       "113           2023-08-17             1.170000e+24  \n",
       "114           2023-08-17             2.100000e+25  \n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_max_compute_df[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Training compute (FLOP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPPNet</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>3.410000e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seq2Seq LSTM</td>\n",
       "      <td>Google</td>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>5.600000e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AlphaGo Fan</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>3.800000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GNMT</td>\n",
       "      <td>Google</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>6.900000e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AlphaGo Master</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1.500000e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>1.170000e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Google</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2.530000e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>2.100000e+25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       System Organization Publication date  \\\n",
       "4                      SPPNet    Microsoft       2014-06-18   \n",
       "5                Seq2Seq LSTM       Google       2014-09-10   \n",
       "8                 AlphaGo Fan     DeepMind       2015-10-01   \n",
       "12                       GNMT       Google       2016-09-26   \n",
       "15             AlphaGo Master     DeepMind       2017-01-01   \n",
       "83   Megatron-Turing NLG 530B    Microsoft       2021-10-11   \n",
       "92                PaLM (540B)       Google       2022-04-04   \n",
       "104                     GPT-4       OpenAI       2023-03-15   \n",
       "\n",
       "     Training compute (FLOP)  \n",
       "4               3.410000e+18  \n",
       "5               5.600000e+19  \n",
       "8               3.800000e+20  \n",
       "12              6.900000e+21  \n",
       "15              1.500000e+23  \n",
       "83              1.170000e+24  \n",
       "92              2.530000e+24  \n",
       "104             2.100000e+25  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_max = 0\n",
    "current_max_org = \"Google\"\n",
    "global_max_rows = []\n",
    "for i, row in company_max_compute_df.iterrows():\n",
    "    if row[\"Training compute (FLOP)\"] > current_max:\n",
    "        current_max = row[\"Training compute (FLOP)\"]\n",
    "        if row[\"Organization\"] != current_max_org:\n",
    "            current_max_org = row[\"Organization\"]\n",
    "            global_max_rows.append(row)\n",
    "global_max_df = pd.DataFrame(global_max_rows)\n",
    "global_max_df[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "OpenAI TI7 DOTA 1v1"
          ],
          [
           "GPT"
          ],
          [
           "GPT-2"
          ],
          [
           "Hide and Seek"
          ],
          [
           "Rubik's cube"
          ],
          [
           "OpenAI Five Rerun"
          ],
          [
           "OpenAI Five"
          ],
          [
           "GPT-3 175B (davinci)"
          ],
          [
           "iGPT-XL"
          ],
          [
           "iGPT-L"
          ],
          [
           "DALL-E"
          ],
          [
           "CLIP (ViT L/14@336px)"
          ],
          [
           "Whisper"
          ],
          [
           "GPT-4"
          ],
          [
           null
          ]
         ],
         "hovertemplate": "Organization=OpenAI<br>Publication date=%{x}<br>Largest published training run to date (FLOP)=%{y}<br>System=%{customdata[0]}<extra></extra>",
         "legendgroup": "OpenAI",
         "line": {
          "color": "#636efa",
          "dash": "solid",
          "shape": "hv"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "OpenAI",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08-11T00:00:00",
          "2018-06-01T00:00:00",
          "2019-02-14T00:00:00",
          "2019-09-17T00:00:00",
          "2019-10-15T00:00:00",
          "2019-12-13T00:00:00",
          "2019-12-13T00:00:00",
          "2020-05-28T00:00:00",
          "2020-06-17T00:00:00",
          "2020-06-17T00:00:00",
          "2021-01-05T00:00:00",
          "2021-01-05T00:00:00",
          "2022-09-21T00:00:00",
          "2023-03-15T00:00:00",
          "2023-08-17T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          605000000000000000000,
          605000000000000000000,
          1.49e+21,
          1.49e+21,
          1.49e+21,
          1.3e+22,
          6.7e+22,
          3.14e+23,
          3.14e+23,
          3.14e+23,
          3.14e+23,
          3.14e+23,
          3.14e+23,
          2.1e+25,
          2.1e+25
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Unsupervised High-level Feature Learner"
          ],
          [
           "Word2Vec (large)"
          ],
          [
           "TransE"
          ],
          [
           "Seq2Seq LSTM"
          ],
          [
           "GoogLeNet / InceptionV1"
          ],
          [
           "GNMT"
          ],
          [
           "Xception"
          ],
          [
           "NASv3 (CIFAR-10)"
          ],
          [
           "MoE"
          ],
          [
           "Transformer"
          ],
          [
           "Transformer"
          ],
          [
           "JFT"
          ],
          [
           "PNASNet-5"
          ],
          [
           "AmoebaNet-A (F=448)"
          ],
          [
           "BERT-Large"
          ],
          [
           "Hanabi 4 player"
          ],
          [
           "MnasNet-A3"
          ],
          [
           "MnasNet-A1 + SSDLite"
          ],
          [
           "T5-3B"
          ],
          [
           "T5-11B"
          ],
          [
           "Noisy Student (L2)"
          ],
          [
           "Meena"
          ],
          [
           "ALBERT-xxlarge"
          ],
          [
           "ELECTRA"
          ],
          [
           "GShard (dense)"
          ],
          [
           "GShard (600B)"
          ],
          [
           "ViT-H/14"
          ],
          [
           "Switch"
          ],
          [
           "Meta Pseudo Labels"
          ],
          [
           "ProtT5-XXL"
          ],
          [
           "Transformer local-attention (NesT-B)"
          ],
          [
           "ViT-G/14"
          ],
          [
           "ALIGN"
          ],
          [
           "EfficientNetV2"
          ],
          [
           "FLAN"
          ],
          [
           "Primer"
          ],
          [
           "LaMDA"
          ],
          [
           "PaLM (540B)"
          ],
          [
           "LiMoE"
          ],
          [
           "Parti"
          ],
          [
           "Minerva (540B)"
          ],
          [
           "PaLM 2"
          ],
          [
           null
          ]
         ],
         "hovertemplate": "Organization=Google<br>Publication date=%{x}<br>Largest published training run to date (FLOP)=%{y}<br>System=%{customdata[0]}<extra></extra>",
         "legendgroup": "Google",
         "line": {
          "color": "#EF553B",
          "dash": "solid",
          "shape": "hv"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Google",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2012-07-12T00:00:00",
          "2013-10-16T00:00:00",
          "2013-12-05T00:00:00",
          "2014-09-10T00:00:00",
          "2015-06-07T00:00:00",
          "2016-09-26T00:00:00",
          "2016-10-07T00:00:00",
          "2016-11-05T00:00:00",
          "2017-01-23T00:00:00",
          "2017-06-12T00:00:00",
          "2017-06-12T00:00:00",
          "2017-08-04T00:00:00",
          "2017-12-02T00:00:00",
          "2018-02-05T00:00:00",
          "2018-10-11T00:00:00",
          "2019-02-01T00:00:00",
          "2019-05-29T00:00:00",
          "2019-05-29T00:00:00",
          "2019-10-23T00:00:00",
          "2019-10-23T00:00:00",
          "2019-11-11T00:00:00",
          "2020-01-28T00:00:00",
          "2020-02-09T00:00:00",
          "2020-03-23T00:00:00",
          "2020-06-30T00:00:00",
          "2020-06-30T00:00:00",
          "2020-09-28T00:00:00",
          "2021-01-11T00:00:00",
          "2021-03-01T00:00:00",
          "2021-05-04T00:00:00",
          "2021-05-26T00:00:00",
          "2021-06-08T00:00:00",
          "2021-06-11T00:00:00",
          "2021-06-23T00:00:00",
          "2021-09-03T00:00:00",
          "2022-01-24T00:00:00",
          "2022-02-10T00:00:00",
          "2022-04-04T00:00:00",
          "2022-06-06T00:00:00",
          "2022-06-22T00:00:00",
          "2022-06-29T00:00:00",
          "2023-05-10T00:00:00",
          "2023-08-17T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          600000000000000000,
          600000000000000000,
          1340000000000000000,
          56000000000000000000,
          56000000000000000000,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          6.9e+21,
          1.04e+22,
          4.05e+22,
          4.05e+22,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          1.12e+23,
          2.15e+23,
          2.15e+23,
          2.15e+23,
          2.15e+23,
          3.55e+23,
          2.53e+24,
          2.53e+24,
          2.53e+24,
          2.74e+24,
          7.34e+24,
          7.34e+24
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "SPPNet"
          ],
          [
           "MSRA (C, PReLU)"
          ],
          [
           "ResNet-152 (ImageNet)"
          ],
          [
           "Turing NLG"
          ],
          [
           "DeBERTa"
          ],
          [
           "Megatron-Turing NLG 530B"
          ],
          [
           "NÃœWA"
          ],
          [
           null
          ]
         ],
         "hovertemplate": "Organization=Microsoft<br>Publication date=%{x}<br>Largest published training run to date (FLOP)=%{y}<br>System=%{customdata[0]}<extra></extra>",
         "legendgroup": "Microsoft",
         "line": {
          "color": "#00cc96",
          "dash": "solid",
          "shape": "hv"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Microsoft",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2014-06-18T00:00:00",
          "2015-02-06T00:00:00",
          "2015-12-10T00:00:00",
          "2020-02-13T00:00:00",
          "2021-06-10T00:00:00",
          "2021-10-11T00:00:00",
          "2021-11-24T00:00:00",
          "2023-08-17T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          3410000000000000000,
          24000000000000000000,
          24000000000000000000,
          1.57e+22,
          1.57e+22,
          1.17e+24,
          1.17e+24,
          1.17e+24
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "DQN"
          ],
          [
           "AlphaGo Fan"
          ],
          [
           "AlphaGo Lee"
          ],
          [
           "AlphaGo Master"
          ],
          [
           "AlphaGo Zero"
          ],
          [
           "AlphaZero"
          ],
          [
           "IMPALA"
          ],
          [
           "Population-based DRL"
          ],
          [
           "BigGAN-deep 512x512"
          ],
          [
           "Hanabi 4 player"
          ],
          [
           "FTW"
          ],
          [
           "AlphaStar"
          ],
          [
           "MuZero"
          ],
          [
           "AlphaFold"
          ],
          [
           "GOAT"
          ],
          [
           "Gopher"
          ],
          [
           "AlphaCode"
          ],
          [
           "Chinchilla"
          ],
          [
           "Gato"
          ],
          [
           null
          ]
         ],
         "hovertemplate": "Organization=DeepMind<br>Publication date=%{x}<br>Largest published training run to date (FLOP)=%{y}<br>System=%{customdata[0]}<extra></extra>",
         "legendgroup": "DeepMind",
         "line": {
          "color": "#ab63fa",
          "dash": "solid",
          "shape": "hv"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "DeepMind",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2013-12-19T00:00:00",
          "2015-10-01T00:00:00",
          "2016-01-27T00:00:00",
          "2017-01-01T00:00:00",
          "2017-10-18T00:00:00",
          "2017-12-05T00:00:00",
          "2018-02-05T00:00:00",
          "2018-07-03T00:00:00",
          "2018-09-28T00:00:00",
          "2019-02-01T00:00:00",
          "2019-05-31T00:00:00",
          "2019-10-30T00:00:00",
          "2019-11-19T00:00:00",
          "2020-01-15T00:00:00",
          "2021-07-27T00:00:00",
          "2021-12-08T00:00:00",
          "2022-02-02T00:00:00",
          "2022-03-29T00:00:00",
          "2022-05-12T00:00:00",
          "2023-08-17T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          2300000000000000,
          380000000000000000000,
          1.9e+21,
          1.5e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          3.41e+23,
          6.31e+23,
          6.31e+23,
          6.31e+23,
          6.31e+23,
          6.31e+23
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "RetinaNet-R101"
          ],
          [
           "ResNeXt-101 32x48d"
          ],
          [
           "DLRM-2020"
          ],
          [
           "RoBERTa Large"
          ],
          [
           "Pluribus"
          ],
          [
           "DLRM-2021"
          ],
          [
           "wave2vec 2.0 LARGE"
          ],
          [
           "HuBERT"
          ],
          [
           "SEER"
          ],
          [
           "DLRM-2022"
          ],
          [
           "Sparse all-MLP"
          ],
          [
           "OPT-175B"
          ],
          [
           "NLLB"
          ],
          [
           "LLaMA (65B)"
          ],
          [
           null
          ]
         ],
         "hovertemplate": "Organization=Meta<br>Publication date=%{x}<br>Largest published training run to date (FLOP)=%{y}<br>System=%{customdata[0]}<extra></extra>",
         "legendgroup": "Meta",
         "line": {
          "color": "#FFA15A",
          "dash": "solid",
          "shape": "hv"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Meta",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2017-08-07T00:00:00",
          "2018-05-02T00:00:00",
          "2019-05-31T00:00:00",
          "2019-07-01T00:00:00",
          "2019-07-11T00:00:00",
          "2020-07-01T00:00:00",
          "2020-10-22T00:00:00",
          "2021-07-27T00:00:00",
          "2021-07-29T00:00:00",
          "2021-09-15T00:00:00",
          "2022-04-14T00:00:00",
          "2022-05-02T00:00:00",
          "2022-07-06T00:00:00",
          "2023-02-24T00:00:00",
          "2023-08-17T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          2070000000000000000,
          2070000000000000000,
          4000000000000000000,
          4.15e+21,
          4.15e+21,
          4.15e+21,
          4.15e+21,
          5.54e+21,
          5.54e+21,
          5.54e+21,
          5.54e+21,
          4.3e+23,
          4.3e+23,
          5.5e+23,
          5.5e+23
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "black"
         },
         "mode": "markers+text",
         "name": "Changes in leader",
         "text": [
          "SPPNet",
          "Seq2Seq LSTM",
          "AlphaGo Fan",
          "GNMT",
          "AlphaGo Master",
          "Megatron-Turing NLG 530B",
          "PaLM (540B)",
          "GPT-4"
         ],
         "textposition": "top left",
         "type": "scatter",
         "x": [
          "2014-06-18T00:00:00",
          "2014-09-10T00:00:00",
          "2015-10-01T00:00:00",
          "2016-09-26T00:00:00",
          "2017-01-01T00:00:00",
          "2021-10-11T00:00:00",
          "2022-04-04T00:00:00",
          "2023-03-15T00:00:00"
         ],
         "y": [
          3410000000000000000,
          56000000000000000000,
          380000000000000000000,
          6.9e+21,
          1.5e+23,
          1.17e+24,
          2.53e+24,
          2.1e+25
         ]
        },
        {
         "line": {
          "color": "black"
         },
         "marker": {
          "symbol": "x"
         },
         "mode": "markers+text",
         "name": "Other notable systems",
         "text": [
          "GPT-3 (175B)"
         ],
         "textposition": "top left",
         "type": "scatter",
         "x": [
          "2020-05-28T00:00:00"
         ],
         "y": [
          3.14e+23
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "font": {
         "size": 10
        },
        "height": 415,
        "legend": {
         "orientation": "h",
         "title": {
          "text": ""
         },
         "tracegroupgap": 0,
         "x": 0,
         "y": -0.15
        },
        "margin": {
         "b": 0,
         "l": 20,
         "r": 20,
         "t": 20
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 400,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "nticks": 12,
         "range": [
          "2011-01-01T00:00:00",
          "2023-08-17"
         ],
         "title": {
          "text": "Publication date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Largest published training run to date (FLOP)"
         },
         "type": "log"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a line plot\n",
    "fig = px.line(\n",
    "    company_max_compute_df[company_max_compute_df[\"Organization\"].isin([\"Google\", \"DeepMind\", \"OpenAI\", \"Meta\", \"Microsoft\"])],\n",
    "    x=\"Publication date\", \n",
    "    y=\"Training compute (FLOP)\", \n",
    "    line_shape=\"hv\",\n",
    "    color=\"Organization\",\n",
    "    labels={\"Training compute (FLOP)\": \"Largest published training run to date (FLOP)\"},\n",
    "    category_orders={\"Organization\": [\"OpenAI\", \"Google\", \"Microsoft\", \"DeepMind\", \"Meta\"]},\n",
    "    hover_data=[\"System\"],\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=global_max_df[\"Publication date\"],\n",
    "        y=global_max_df[\"Training compute (FLOP)\"],\n",
    "        text=global_max_df[\"System\"],\n",
    "        textposition=\"top left\",\n",
    "        line={\"color\": \"black\"},\n",
    "        mode=\"markers+text\",\n",
    "        name=\"Changes in leader\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.to_datetime([\"2020-05-28\"]),\n",
    "        y=[3.14e23],\n",
    "        text=[\"GPT-3 (175B)\"],\n",
    "        textposition=\"top left\",\n",
    "        line={\"color\": \"black\"},\n",
    "        mode=\"markers+text\",\n",
    "        marker_symbol=\"x\",\n",
    "        name=\"Other notable systems\",\n",
    "    )\n",
    ")\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(\n",
    "#         x=pd.to_datetime([\"2020-05-28\", \"2023-02-24\"]),\n",
    "#         y=[3.14e23, 5.50e23],\n",
    "#         text=[\"GPT-3 (175B)\", \"LLaMA (65B)\"],\n",
    "#         textposition=[\"top left\", \"middle left\"],\n",
    "#         line={\"color\": \"black\"},\n",
    "#         mode=\"markers+text\",\n",
    "#         marker_symbol=\"x\",\n",
    "#         name=\"Other notable systems\",\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Convert year to datetime\n",
    "fig.update_yaxes(type=\"log\")\n",
    "# Show all years on x axis\n",
    "fig.update_xaxes(nticks=12)\n",
    "# Make sure the labels are fully shown\n",
    "fig.update_xaxes(range=[pd.to_datetime(2011, format=\"%Y\"), datetime.now().date()])\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title=\"\",\n",
    "        orientation=\"h\",\n",
    "        # yanchor=\"top\",\n",
    "        y=-0.15,\n",
    "        # xanchor=\"center\",\n",
    "        x=0,\n",
    "    ),\n",
    ")\n",
    "# Edit figure layout\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=400,\n",
    "    height=415,\n",
    "    font=dict(size=10),\n",
    "    margin=dict(l=20, r=20, t=20, b=0),\n",
    ")\n",
    "\n",
    "save_plot(fig, result_file_location, 'companies_largest_compute_all')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Largest training runs for any company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from the Parameters, Compute and Data Trends in ML sheet\n",
    "sheet_id = '1AAIebjNsnJj_uKALHbXNfn3_YsT6sHXtCU0q7OIPuc4'\n",
    "data_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet='\n",
    "df = pd.read_csv(data_url + 'ALL%20ML%20SYSTEMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Training compute (FLOP)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejected samples\n",
    "# We don't think the full training run was actually done\n",
    "df.drop(df[df[\"System\"] == \"Megatron-LM (1T)\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Publication date'] = pd.to_datetime(df['Publication date'])  # Ensure date column is in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Publication date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization Categorization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time notes</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Training compute cost (2020 USD)</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Self-supervised training</th>\n",
       "      <th>Compute Sponsor Categorization</th>\n",
       "      <th>Epistemic status</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>557</td>\n",
       "      <td>Theseus</td>\n",
       "      <td>Other</td>\n",
       "      <td>Maze solving</td>\n",
       "      <td>Bell Laboratories</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Claude Shannon</td>\n",
       "      <td>1950-07-02</td>\n",
       "      <td>Mighty Mouse</td>\n",
       "      <td>https://www.technologyreview.com/2018/12/19/13...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>551</td>\n",
       "      <td>Perceptron Mark I</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Binary classification</td>\n",
       "      <td>Cornell Aeronautical Laboratory,Cornell Univer...</td>\n",
       "      <td>Industry</td>\n",
       "      <td>F Rosenblatt</td>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>The Perceptronâ€”a perceiving and recognizing au...</td>\n",
       "      <td>https://blogs.umass.edu/brain-wars/files/2016/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-15 18:01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550</td>\n",
       "      <td>Pandemonium (morse)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Morse translation</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Academia</td>\n",
       "      <td>OG Selfridge</td>\n",
       "      <td>1959-02-01</td>\n",
       "      <td>Pandemonium: A Paradigm for Learning</td>\n",
       "      <td>https://aitopics.org/doc/classics:504E1BAC/</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academia</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 18:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>549</td>\n",
       "      <td>Samuel Neural Checkers</td>\n",
       "      <td>Games</td>\n",
       "      <td>Checkers</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Arthur L. Samuel</td>\n",
       "      <td>1959-07-01</td>\n",
       "      <td>Some studies in machine learning using the gam...</td>\n",
       "      <td>https://ieeexplore.ieee.org/abstract/document/...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546</td>\n",
       "      <td>ADALINE</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Pattern recognition</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Academia</td>\n",
       "      <td>Widrow and Hoff</td>\n",
       "      <td>1960-06-30</td>\n",
       "      <td>Adaptive switching circuits</td>\n",
       "      <td>https://isl.stanford.edu/~widrow/papers/c1960a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>17</td>\n",
       "      <td>BLOOM</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language model</td>\n",
       "      <td>Hugging Face,BigScience</td>\n",
       "      <td>Research Collective</td>\n",
       "      <td>Margaret Mitchell, Giada Pistilli, Yacine Jern...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>BigScience Large Open-science Open-access Mult...</td>\n",
       "      <td>https://huggingface.co/bigscience/bloom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-04 13:13:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>14</td>\n",
       "      <td>AR-LDM</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Text-to-image</td>\n",
       "      <td>Alibaba,University of Waterloo,Vector Institute</td>\n",
       "      <td>Industry - Academia Collaboration (Industry le...</td>\n",
       "      <td>Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, We...</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>Synthesizing Coherent Story with Auto-Regressi...</td>\n",
       "      <td>https://arxiv.org/abs/2211.10950</td>\n",
       "      <td>...</td>\n",
       "      <td>8 NVIDIA A100 GPUs for 8 days</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confident</td>\n",
       "      <td>Conditioned diffusion models have demonstrated...</td>\n",
       "      <td>2023-08-01 09:57:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>10</td>\n",
       "      <td>LLaMA (65B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Hugo Touvron, Thibaut Lavril, Gautier Izacard,...</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>LLaMA: Open and Efficient Foundation Language ...</td>\n",
       "      <td>https://arxiv.org/abs/2302.13971</td>\n",
       "      <td>...</td>\n",
       "      <td>\"When training a 65B-parameter model, our code...</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>Supervised</td>\n",
       "      <td>1179384.75</td>\n",
       "      <td>1023384 processor-hours on A100 GPUs. May 2023...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Likely</td>\n",
       "      <td>We introduce LLaMA, a collection of foundation...</td>\n",
       "      <td>2023-07-28 16:26:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>9</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>https://arxiv.org/abs/2303.08774</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-06 22:13:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>8</td>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Andrew M. Dai, David R. So, Dmitry Lepikhin, J...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>PaLM 2 Technical Report</td>\n",
       "      <td>https://ai.google/static/documents/palm2techre...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2 was trained on TPU v4 according to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We introduce PaLM 2, a new state-of-the-art la...</td>\n",
       "      <td>2023-08-10 15:21:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                  System      Domain                   Task  \\\n",
       "0      557                 Theseus       Other           Maze solving   \n",
       "1      551       Perceptron Mark I      Vision  Binary classification   \n",
       "2      550     Pandemonium (morse)       Other      Morse translation   \n",
       "3      549  Samuel Neural Checkers       Games               Checkers   \n",
       "4      546                 ADALINE      Vision    Pattern recognition   \n",
       "..     ...                     ...         ...                    ...   \n",
       "179     17                   BLOOM    Language         Language model   \n",
       "180     14                  AR-LDM  Multimodal          Text-to-image   \n",
       "181     10             LLaMA (65B)    Language     Language modelling   \n",
       "182      9                   GPT-4  Multimodal     Language modelling   \n",
       "183      8                  PaLM 2    Language     Language modelling   \n",
       "\n",
       "                                          Organization  \\\n",
       "0                                    Bell Laboratories   \n",
       "1    Cornell Aeronautical Laboratory,Cornell Univer...   \n",
       "2                Massachusetts Institute of Technology   \n",
       "3                                                  IBM   \n",
       "4                                  Stanford University   \n",
       "..                                                 ...   \n",
       "179                            Hugging Face,BigScience   \n",
       "180    Alibaba,University of Waterloo,Vector Institute   \n",
       "181                                            Meta AI   \n",
       "182                                             OpenAI   \n",
       "183                                             Google   \n",
       "\n",
       "                           Organization Categorization  \\\n",
       "0                                             Industry   \n",
       "1                                             Industry   \n",
       "2                                             Academia   \n",
       "3                                             Industry   \n",
       "4                                             Academia   \n",
       "..                                                 ...   \n",
       "179                                Research Collective   \n",
       "180  Industry - Academia Collaboration (Industry le...   \n",
       "181                                           Industry   \n",
       "182                                           Industry   \n",
       "183                                           Industry   \n",
       "\n",
       "                                               Authors Publication date  \\\n",
       "0                                       Claude Shannon       1950-07-02   \n",
       "1                                         F Rosenblatt       1957-01-01   \n",
       "2                                         OG Selfridge       1959-02-01   \n",
       "3                                     Arthur L. Samuel       1959-07-01   \n",
       "4                                      Widrow and Hoff       1960-06-30   \n",
       "..                                                 ...              ...   \n",
       "179  Margaret Mitchell, Giada Pistilli, Yacine Jern...       2022-11-08   \n",
       "180  Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, We...       2022-11-20   \n",
       "181  Hugo Touvron, Thibaut Lavril, Gautier Izacard,...       2023-02-24   \n",
       "182                                             OpenAI       2023-03-15   \n",
       "183  Andrew M. Dai, David R. So, Dmitry Lepikhin, J...       2023-05-10   \n",
       "\n",
       "                                             Reference  \\\n",
       "0                                         Mighty Mouse   \n",
       "1    The Perceptronâ€”a perceiving and recognizing au...   \n",
       "2                 Pandemonium: A Paradigm for Learning   \n",
       "3    Some studies in machine learning using the gam...   \n",
       "4                          Adaptive switching circuits   \n",
       "..                                                 ...   \n",
       "179  BigScience Large Open-science Open-access Mult...   \n",
       "180  Synthesizing Coherent Story with Auto-Regressi...   \n",
       "181  LLaMA: Open and Efficient Foundation Language ...   \n",
       "182                             GPT-4 Technical Report   \n",
       "183                            PaLM 2 Technical Report   \n",
       "\n",
       "                                                  Link  ...  \\\n",
       "0    https://www.technologyreview.com/2018/12/19/13...  ...   \n",
       "1    https://blogs.umass.edu/brain-wars/files/2016/...  ...   \n",
       "2          https://aitopics.org/doc/classics:504E1BAC/  ...   \n",
       "3    https://ieeexplore.ieee.org/abstract/document/...  ...   \n",
       "4    https://isl.stanford.edu/~widrow/papers/c1960a...  ...   \n",
       "..                                                 ...  ...   \n",
       "179            https://huggingface.co/bigscience/bloom  ...   \n",
       "180                   https://arxiv.org/abs/2211.10950  ...   \n",
       "181                   https://arxiv.org/abs/2302.13971  ...   \n",
       "182                   https://arxiv.org/abs/2303.08774  ...   \n",
       "183  https://ai.google/static/documents/palm2techre...  ...   \n",
       "\n",
       "                                   Training time notes Training hardware  \\\n",
       "0                                                  NaN               NaN   \n",
       "1                                                  NaN               NaN   \n",
       "2                                                  NaN               NaN   \n",
       "3                                                  NaN               NaN   \n",
       "4                                                  NaN               NaN   \n",
       "..                                                 ...               ...   \n",
       "179                                                NaN               NaN   \n",
       "180                      8 NVIDIA A100 GPUs for 8 days       NVIDIA A100   \n",
       "181  \"When training a 65B-parameter model, our code...       NVIDIA A100   \n",
       "182                                                NaN               NaN   \n",
       "183                                                NaN               NaN   \n",
       "\n",
       "                     Approach  Training compute cost (2020 USD)  \\\n",
       "0                         NaN                               NaN   \n",
       "1                         NaN                               NaN   \n",
       "2                         NaN                               NaN   \n",
       "3                         NaN                               NaN   \n",
       "4                         NaN                               NaN   \n",
       "..                        ...                               ...   \n",
       "179  Self-supervised learning                               NaN   \n",
       "180                       NaN                               NaN   \n",
       "181                Supervised                        1179384.75   \n",
       "182  Self-supervised learning                               NaN   \n",
       "183                       NaN                               NaN   \n",
       "\n",
       "                                    Compute cost notes  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "179                                                NaN   \n",
       "180                                                NaN   \n",
       "181  1023384 processor-hours on A100 GPUs. May 2023...   \n",
       "182                                                NaN   \n",
       "183  PaLM 2 was trained on TPU v4 according to the ...   \n",
       "\n",
       "     Self-supervised training Compute Sponsor Categorization Epistemic status  \\\n",
       "0                         NaN                       Industry              NaN   \n",
       "1                         NaN                       Industry              NaN   \n",
       "2                         NaN                       Academia      Speculative   \n",
       "3                         NaN                       Industry              NaN   \n",
       "4                         NaN                       Academia              NaN   \n",
       "..                        ...                            ...              ...   \n",
       "179                       Yes                            NaN              NaN   \n",
       "180                       NaN                            NaN        Confident   \n",
       "181                       NaN                       Industry           Likely   \n",
       "182                       Yes                            NaN              NaN   \n",
       "183                       NaN                       Industry              NaN   \n",
       "\n",
       "                                              Abstract        Last Modified  \n",
       "0                                                  NaN  2023-05-29 20:51:04  \n",
       "1                                                  NaN  2023-08-15 18:01:22  \n",
       "2                                                  NaN  2023-07-25 18:00:25  \n",
       "3                                                  NaN  2023-05-29 20:51:04  \n",
       "4                                                  NaN  2023-05-29 20:51:04  \n",
       "..                                                 ...                  ...  \n",
       "179                                                NaN  2023-08-04 13:13:07  \n",
       "180  Conditioned diffusion models have demonstrated...  2023-08-01 09:57:26  \n",
       "181  We introduce LLaMA, a collection of foundation...  2023-07-28 16:26:34  \n",
       "182                                                NaN  2023-08-06 22:13:42  \n",
       "183  We introduce PaLM 2, a new state-of-the-art la...  2023-08-10 15:21:27  \n",
       "\n",
       "[184 rows x 34 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with the top 20 largest values for 'Training compute (FLOP)\" column since 2021\n",
    "top_20_compute_df = df[df['Publication date'] >= pd.to_datetime('2021-01-01')].nlargest(20, 'Training compute (FLOP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization Categorization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>...</th>\n",
       "      <th>Training time notes</th>\n",
       "      <th>Training hardware</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Training compute cost (2020 USD)</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Self-supervised training</th>\n",
       "      <th>Compute Sponsor Categorization</th>\n",
       "      <th>Epistemic status</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>9</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-06 22:13:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Andrew M. Dai, David R. So, Dmitry Lepikhin, J...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>PaLM 2 Technical Report</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2 was trained on TPU v4 according to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We introduce PaLM 2, a new state-of-the-art la...</td>\n",
       "      <td>2023-08-10 15:21:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>26</td>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Quantitative Reasoning Problems</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aitor Lewkowycz, Anders Andreassen, David Doha...</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>Solving Quantitative Reasoning Problems with L...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>3267257.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language models have achieved remarkable perfo...</td>\n",
       "      <td>2023-08-10 15:22:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163</td>\n",
       "      <td>43</td>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aakanksha Chowdhery, Sharan Narang, Jacob Devl...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>PaLM: Scaling Language Modeling with Pathways</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>3232806.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models have been shown to achie...</td>\n",
       "      <td>2023-08-11 19:08:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>Megatron-Turing NLG 530B</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft,NVIDIA</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Ali Alvi, Paresh Kharya</td>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>Using DeepSpeed and Megatron to Train Megatron...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>3046994.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pretrained general-purpose language models can...</td>\n",
       "      <td>2023-08-15 14:40:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156</td>\n",
       "      <td>62</td>\n",
       "      <td>Gopher</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Jack W. Rae, Sebastian Borgeaud, Trevor Cai, K...</td>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>Scaling Language Models: Methods, Analysis &amp; I...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891638.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We enhance auto-regressive language models by ...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>Training Compute-Optimal Large Language Models</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753491.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We investigate the optimal model size and numb...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>181</td>\n",
       "      <td>10</td>\n",
       "      <td>LLaMA (65B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Hugo Touvron, Thibaut Lavril, Gautier Izacard,...</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>LLaMA: Open and Efficient Foundation Language ...</td>\n",
       "      <td>...</td>\n",
       "      <td>\"When training a 65B-parameter model, our code...</td>\n",
       "      <td>NVIDIA A100</td>\n",
       "      <td>Supervised</td>\n",
       "      <td>1179384.75</td>\n",
       "      <td>1023384 processor-hours on A100 GPUs. May 2023...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Likely</td>\n",
       "      <td>We introduce LLaMA, a collection of foundation...</td>\n",
       "      <td>2023-07-28 16:26:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>166</td>\n",
       "      <td>38</td>\n",
       "      <td>OPT-175B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Susan Zhang, Stephen Roller, Naman Goyal, Mike...</td>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>OPT: Open Pre-trained Transformer Language Models</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654082.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models, which are often trained...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>72</td>\n",
       "      <td>Yuan 1.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inspur</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>Yuan 1.0: Large-Scale Pre-trained Language Mod...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>606364.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recent work like GPT-3 has demonstrated excell...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>159</td>\n",
       "      <td>52</td>\n",
       "      <td>AlphaCode</td>\n",
       "      <td>Language</td>\n",
       "      <td>Code generation</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>Industry</td>\n",
       "      <td>The Alpha Code team</td>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>Competition-Level Code Generation with AlphaCode</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>170</td>\n",
       "      <td>29</td>\n",
       "      <td>Parti</td>\n",
       "      <td>Drawing</td>\n",
       "      <td>Text-to-image</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Lu...</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>Scaling Autoregressive Models for Content-Rich...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>486659.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present the Pathways Autoregressive Text-to...</td>\n",
       "      <td>2023-08-11 19:13:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>145</td>\n",
       "      <td>81</td>\n",
       "      <td>Jurassic-1-Jumbo</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Opher Lieber, Or Sharir, Barak Lenz, Yoav Shoham</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>Jurassic-1: Technical Details and Evaluation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805277.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jurassic-1 is a pair of auto-regressive langua...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>161</td>\n",
       "      <td>49</td>\n",
       "      <td>LaMDA</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Romal Thoppilan, Daniel De Freitas, Jamie Hall...</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>LaMDA: Language Models for Dialog Applications</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484957.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present LaMDA: Language Models for Dialog A...</td>\n",
       "      <td>2023-05-30 18:54:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>Source 1.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Inspur</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>157</td>\n",
       "      <td>59</td>\n",
       "      <td>ERNIE 3.0 Titan</td>\n",
       "      <td>Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baidu</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Shuohuan Wang, Yu Sun, Yang Xiang, Zhihua Wu, ...</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>ERNIE 3.0 Titan: Exploring Larger-scale Knowle...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-24 06:50:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>171</td>\n",
       "      <td>28</td>\n",
       "      <td>YaLM</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Yandex</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>138</td>\n",
       "      <td>89</td>\n",
       "      <td>ALIGN</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Representation Learning</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>ChaoJia,YinfeiYang,YeXia,Yi-TingChen,ZaranaPar...</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>Scaling up visual and vision-language represen...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>357760.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-trained representations are becoming cruci...</td>\n",
       "      <td>2023-08-11 18:01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>175</td>\n",
       "      <td>24</td>\n",
       "      <td>AlexaTM 20B</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Saleh Soltan, Shankar Ananthakrishnan, Jack Fi...</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>AlexaTM 20B: Few-Shot Learning Using a Large-S...</td>\n",
       "      <td>...</td>\n",
       "      <td>See p.5 of the paper: \"We trained AlexaTM 20B ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this work, we demonstrate that multilingual...</td>\n",
       "      <td>2023-06-08 00:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>179</td>\n",
       "      <td>17</td>\n",
       "      <td>BLOOM</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language model</td>\n",
       "      <td>Hugging Face,BigScience</td>\n",
       "      <td>Research Collective</td>\n",
       "      <td>Margaret Mitchell, Giada Pistilli, Yacine Jern...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>BigScience Large Open-science Open-access Mult...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-supervised learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-04 13:13:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  index                    System      Domain  \\\n",
       "0       182      9                     GPT-4  Multimodal   \n",
       "1       183      8                    PaLM 2    Language   \n",
       "2       173     26            Minerva (540B)    Language   \n",
       "3       163     43               PaLM (540B)    Language   \n",
       "4       150     73  Megatron-Turing NLG 530B    Language   \n",
       "5       156     62                    Gopher    Language   \n",
       "6       162     44                Chinchilla    Language   \n",
       "7       181     10               LLaMA (65B)    Language   \n",
       "8       166     38                  OPT-175B    Language   \n",
       "9       151     72                  Yuan 1.0    Language   \n",
       "10      159     52                 AlphaCode    Language   \n",
       "11      170     29                     Parti     Drawing   \n",
       "12      145     81          Jurassic-1-Jumbo    Language   \n",
       "13      161     49                     LaMDA    Language   \n",
       "14      154     65                Source 1.0    Language   \n",
       "15      157     59           ERNIE 3.0 Titan    Language   \n",
       "16      171     28                      YaLM    Language   \n",
       "17      138     89                     ALIGN  Multimodal   \n",
       "18      175     24               AlexaTM 20B    Language   \n",
       "19      179     17                     BLOOM    Language   \n",
       "\n",
       "                               Task             Organization  \\\n",
       "0                Language modelling                   OpenAI   \n",
       "1                Language modelling                   Google   \n",
       "2   Quantitative Reasoning Problems                   Google   \n",
       "3                Language modelling          Google Research   \n",
       "4                               NaN         Microsoft,NVIDIA   \n",
       "5                Language modelling                 DeepMind   \n",
       "6                Language modelling                 DeepMind   \n",
       "7                Language modelling                  Meta AI   \n",
       "8                Language modelling                  Meta AI   \n",
       "9                               NaN                   Inspur   \n",
       "10                  Code generation                 DeepMind   \n",
       "11                    Text-to-image          Google Research   \n",
       "12                              NaN                AI21 Labs   \n",
       "13               Language modelling                   Google   \n",
       "14               Language modelling                   Inspur   \n",
       "15                              NaN                    Baidu   \n",
       "16               Language modelling                   Yandex   \n",
       "17          Representation Learning          Google Research   \n",
       "18               Language modelling                   Amazon   \n",
       "19                   Language model  Hugging Face,BigScience   \n",
       "\n",
       "   Organization Categorization  \\\n",
       "0                     Industry   \n",
       "1                     Industry   \n",
       "2                     Industry   \n",
       "3                     Industry   \n",
       "4                     Industry   \n",
       "5                     Industry   \n",
       "6                     Industry   \n",
       "7                     Industry   \n",
       "8                     Industry   \n",
       "9                     Industry   \n",
       "10                    Industry   \n",
       "11                    Industry   \n",
       "12                    Industry   \n",
       "13                    Industry   \n",
       "14                    Industry   \n",
       "15                    Industry   \n",
       "16                    Industry   \n",
       "17                    Industry   \n",
       "18                    Industry   \n",
       "19         Research Collective   \n",
       "\n",
       "                                              Authors Publication date  \\\n",
       "0                                              OpenAI       2023-03-15   \n",
       "1   Andrew M. Dai, David R. So, Dmitry Lepikhin, J...       2023-05-10   \n",
       "2   Aitor Lewkowycz, Anders Andreassen, David Doha...       2022-06-29   \n",
       "3   Aakanksha Chowdhery, Sharan Narang, Jacob Devl...       2022-04-04   \n",
       "4                             Ali Alvi, Paresh Kharya       2021-10-11   \n",
       "5   Jack W. Rae, Sebastian Borgeaud, Trevor Cai, K...       2021-12-08   \n",
       "6   Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...       2022-03-29   \n",
       "7   Hugo Touvron, Thibaut Lavril, Gautier Izacard,...       2023-02-24   \n",
       "8   Susan Zhang, Stephen Roller, Naman Goyal, Mike...       2022-05-02   \n",
       "9   Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhan...       2021-10-12   \n",
       "10                                The Alpha Code team       2022-02-02   \n",
       "11  Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Lu...       2022-06-22   \n",
       "12   Opher Lieber, Or Sharir, Barak Lenz, Yoav Shoham       2021-08-11   \n",
       "13  Romal Thoppilan, Daniel De Freitas, Jamie Hall...       2022-02-10   \n",
       "14                                                NaN       2021-11-10   \n",
       "15  Shuohuan Wang, Yu Sun, Yang Xiang, Zhihua Wu, ...       2021-12-23   \n",
       "16                                                NaN       2022-06-23   \n",
       "17  ChaoJia,YinfeiYang,YeXia,Yi-TingChen,ZaranaPar...       2021-06-11   \n",
       "18  Saleh Soltan, Shankar Ananthakrishnan, Jack Fi...       2022-08-02   \n",
       "19  Margaret Mitchell, Giada Pistilli, Yacine Jern...       2022-11-08   \n",
       "\n",
       "                                            Reference  ...  \\\n",
       "0                              GPT-4 Technical Report  ...   \n",
       "1                             PaLM 2 Technical Report  ...   \n",
       "2   Solving Quantitative Reasoning Problems with L...  ...   \n",
       "3       PaLM: Scaling Language Modeling with Pathways  ...   \n",
       "4   Using DeepSpeed and Megatron to Train Megatron...  ...   \n",
       "5   Scaling Language Models: Methods, Analysis & I...  ...   \n",
       "6      Training Compute-Optimal Large Language Models  ...   \n",
       "7   LLaMA: Open and Efficient Foundation Language ...  ...   \n",
       "8   OPT: Open Pre-trained Transformer Language Models  ...   \n",
       "9   Yuan 1.0: Large-Scale Pre-trained Language Mod...  ...   \n",
       "10   Competition-Level Code Generation with AlphaCode  ...   \n",
       "11  Scaling Autoregressive Models for Content-Rich...  ...   \n",
       "12       Jurassic-1: Technical Details and Evaluation  ...   \n",
       "13     LaMDA: Language Models for Dialog Applications  ...   \n",
       "14                                                NaN  ...   \n",
       "15  ERNIE 3.0 Titan: Exploring Larger-scale Knowle...  ...   \n",
       "16                                                NaN  ...   \n",
       "17  Scaling up visual and vision-language represen...  ...   \n",
       "18  AlexaTM 20B: Few-Shot Learning Using a Large-S...  ...   \n",
       "19  BigScience Large Open-science Open-access Mult...  ...   \n",
       "\n",
       "                                  Training time notes  Training hardware  \\\n",
       "0                                                 NaN                NaN   \n",
       "1                                                 NaN                NaN   \n",
       "2                                                 NaN                NaN   \n",
       "3                                                 NaN                NaN   \n",
       "4                                                 NaN                NaN   \n",
       "5                                                 NaN                NaN   \n",
       "6                                                 NaN                NaN   \n",
       "7   \"When training a 65B-parameter model, our code...        NVIDIA A100   \n",
       "8                                                 NaN                NaN   \n",
       "9                                                 NaN                NaN   \n",
       "10                                                NaN                NaN   \n",
       "11                                                NaN                NaN   \n",
       "12                                                NaN                NaN   \n",
       "13                                                NaN                NaN   \n",
       "14                                                NaN                NaN   \n",
       "15                                                NaN                NaN   \n",
       "16                                                NaN                NaN   \n",
       "17                                                NaN                NaN   \n",
       "18  See p.5 of the paper: \"We trained AlexaTM 20B ...                NaN   \n",
       "19                                                NaN                NaN   \n",
       "\n",
       "                    Approach Training compute cost (2020 USD)  \\\n",
       "0   Self-supervised learning                              NaN   \n",
       "1                        NaN                              NaN   \n",
       "2   Self-supervised learning                       3267257.75   \n",
       "3   Self-supervised learning                       3232806.53   \n",
       "4   Self-supervised learning                       3046994.09   \n",
       "5                        NaN                        891638.80   \n",
       "6                        NaN                        753491.58   \n",
       "7                 Supervised                       1179384.75   \n",
       "8                        NaN                       1654082.50   \n",
       "9                        NaN                        606364.75   \n",
       "10                       NaN                              NaN   \n",
       "11  Self-supervised learning                        486659.77   \n",
       "12                       NaN                        805277.01   \n",
       "13                       NaN                        484957.20   \n",
       "14                       NaN                              NaN   \n",
       "15                       NaN                              NaN   \n",
       "16                       NaN                              NaN   \n",
       "17  Self-supervised learning                        357760.33   \n",
       "18                       NaN                              NaN   \n",
       "19  Self-supervised learning                              NaN   \n",
       "\n",
       "                                   Compute cost notes  \\\n",
       "0                                                 NaN   \n",
       "1   PaLM 2 was trained on TPU v4 according to the ...   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   1023384 processor-hours on A100 GPUs. May 2023...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "   Self-supervised training  Compute Sponsor Categorization Epistemic status  \\\n",
       "0                       Yes                             NaN              NaN   \n",
       "1                       NaN                        Industry              NaN   \n",
       "2                       Yes                        Industry              NaN   \n",
       "3                       Yes                        Industry              NaN   \n",
       "4                       Yes                        Industry              NaN   \n",
       "5                       Yes                        Industry              NaN   \n",
       "6                       Yes                        Industry              NaN   \n",
       "7                       NaN                        Industry           Likely   \n",
       "8                       Yes                        Industry              NaN   \n",
       "9                       Yes                        Industry              NaN   \n",
       "10                      Yes                        Industry              NaN   \n",
       "11                      Yes                        Industry              NaN   \n",
       "12                      Yes                        Industry              NaN   \n",
       "13                      Yes                        Industry              NaN   \n",
       "14                      NaN                             NaN              NaN   \n",
       "15                      NaN                        Industry              NaN   \n",
       "16                      NaN                        Industry              NaN   \n",
       "17                      Yes                        Industry              NaN   \n",
       "18                      NaN                        Industry              NaN   \n",
       "19                      Yes                             NaN              NaN   \n",
       "\n",
       "                                             Abstract        Last Modified  \n",
       "0                                                 NaN  2023-08-06 22:13:42  \n",
       "1   We introduce PaLM 2, a new state-of-the-art la...  2023-08-10 15:21:27  \n",
       "2   Language models have achieved remarkable perfo...  2023-08-10 15:22:32  \n",
       "3   Large language models have been shown to achie...  2023-08-11 19:08:06  \n",
       "4   Pretrained general-purpose language models can...  2023-08-15 14:40:57  \n",
       "5   We enhance auto-regressive language models by ...  2023-05-29 20:51:04  \n",
       "6   We investigate the optimal model size and numb...  2023-05-29 20:51:04  \n",
       "7   We introduce LLaMA, a collection of foundation...  2023-07-28 16:26:34  \n",
       "8   Large language models, which are often trained...  2023-05-29 20:51:04  \n",
       "9   Recent work like GPT-3 has demonstrated excell...  2023-05-29 20:51:04  \n",
       "10                                                NaN  2023-05-29 20:51:04  \n",
       "11  We present the Pathways Autoregressive Text-to...  2023-08-11 19:13:21  \n",
       "12  Jurassic-1 is a pair of auto-regressive langua...  2023-05-29 20:51:04  \n",
       "13  We present LaMDA: Language Models for Dialog A...  2023-05-30 18:54:45  \n",
       "14                                                NaN  2023-05-29 20:51:04  \n",
       "15                                                NaN  2023-07-24 06:50:16  \n",
       "16                                                NaN  2023-05-29 20:51:04  \n",
       "17  Pre-trained representations are becoming cruci...  2023-08-11 18:01:56  \n",
       "18  In this work, we demonstrate that multilingual...  2023-06-08 00:39:43  \n",
       "19                                                NaN  2023-08-04 13:13:07  \n",
       "\n",
       "[20 rows x 35 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_compute_df.reset_index(inplace=True)\n",
    "top_20_compute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://arxiv.org/abs/2303.08774\n",
      "2 https://ai.google/static/documents/palm2techreport.pdf\n",
      "3 https://arxiv.org/abs/2206.14858\n",
      "4 https://arxiv.org/abs/2204.02311\n",
      "5 https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/\n",
      "6 https://deepmind.com/blog/article/language-modelling-at-scale\n",
      "7 https://arxiv.org/abs/2203.15556\n",
      "8 https://arxiv.org/abs/2302.13971\n",
      "9 https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/\n",
      "10 https://arxiv.org/abs/2110.04725\n",
      "11 https://arxiv.org/pdf/2203.07814.pdf\n",
      "12 https://arxiv.org/abs/2206.10789v1\n",
      "13 https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf\n",
      "14 https://arxiv.org/abs/2201.08239\n",
      "15 https://www.gwern.net/docs/ai/scaling/2021-10-11-xinzhiyuan-inspursource10gpt245b.html\n",
      "16 https://arxiv.org/abs/2112.12731\n",
      "17 https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6\n",
      "18 https://arxiv.org/abs/2102.05918\n",
      "19 https://arxiv.org/abs/2208.01448\n",
      "20 https://huggingface.co/bigscience/bloom\n"
     ]
    }
   ],
   "source": [
    "for i, row in top_20_compute_df.iterrows():\n",
    "    print(i+1, row['Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epoch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
