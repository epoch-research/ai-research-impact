{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyalex\n",
    "from pyalex import Authors, Concepts, Institutions, Works\n",
    "\n",
    "from researcher_impact.pyalex_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The polite pool has much faster and more consistent response times. To get into the polite pool, you set your email:\n",
    "pyalex.config.email = \"ben@epochai.org\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCD database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from the Parameters, Compute and Data Trends in ML sheet\n",
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/1AAIebjNsnJj_uKALHbXNfn3_YsT6sHXtCU0q7OIPuc4/export?format=csv#gid=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization Categorization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>...</th>\n",
       "      <th>Training dataset size (GB)</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Training compute cost (2020 USD)</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Self-supervised training</th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Compute Sponsor Categorization</th>\n",
       "      <th>Epistemic status</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Andrew M. Dai, David R. So, Dmitry Lepikhin, J...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>PaLM 2 Technical Report</td>\n",
       "      <td>https://ai.google/static/documents/palm2techre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2 was trained on TPU v4 according to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We introduce PaLM 2, a new state-of-the-art la...</td>\n",
       "      <td>2023-06-06 18:47:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>https://arxiv.org/abs/2303.08774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phenaki</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Video generation</td>\n",
       "      <td>Google Brain, University College London, Unive...</td>\n",
       "      <td>Industry - Academia Collaboration (Industry le...</td>\n",
       "      <td>Ruben Villegas, Mohammad Babaeizadeh, Pieter-J...</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>Phenaki: Variable Length Video Generation From...</td>\n",
       "      <td>https://arxiv.org/abs/2210.02399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Quantitative Reasoning Problems</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aitor Lewkowycz, Anders Andreassen, David Doha...</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>Solving Quantitative Reasoning Problems with L...</td>\n",
       "      <td>https://arxiv.org/abs/2206.14858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$3,267,257.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language models have achieved remarkable perfo...</td>\n",
       "      <td>2023-06-08 00:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aakanksha Chowdhery, Sharan Narang, Jacob Devl...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>PaLM: Scaling Language Modeling with Pathways</td>\n",
       "      <td>https://arxiv.org/abs/2204.02311</td>\n",
       "      <td>228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$3,232,806.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models have been shown to achie...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>AR-LDM</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Text-to-image</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>Industry - Academia Collaboration (Industry le...</td>\n",
       "      <td>Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, We...</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>Synthesizing Coherent Story with Auto-Regressi...</td>\n",
       "      <td>https://arxiv.org/abs/2211.10950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely</td>\n",
       "      <td>Conditioned diffusion models have demonstrated...</td>\n",
       "      <td>2023-06-09 16:04:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>University of Guelph,Canadian Institute for Ad...</td>\n",
       "      <td>Industry - Academia Collaboration</td>\n",
       "      <td>Terrance DeVries, Graham W. Taylor</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>Improved Regularization of Convolutional Neura...</td>\n",
       "      <td>https://arxiv.org/abs/1708.04552</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.yuzeh.com/data/agz-cost.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 16:00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>AltCLIP</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAAI</td>\n",
       "      <td>Academia</td>\n",
       "      <td>Zhongzhi Chen, Guang Liu, Bo-Wen Zhang, Fulong...</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>AltCLIP: Altering the Language Encoder in CLIP...</td>\n",
       "      <td>https://arxiv.org/abs/2211.06679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely</td>\n",
       "      <td>In this work, we present a conceptually simple...</td>\n",
       "      <td>2023-06-09 16:04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ALM 1.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>BAAI</td>\n",
       "      <td>Academia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALM 1.0</td>\n",
       "      <td>https://github.com/FlagAI-Open/FlagAI/blob/mas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 16:06:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>MusicGen</td>\n",
       "      <td>Audio</td>\n",
       "      <td>Audio generation</td>\n",
       "      <td>Meta AI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, ...</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>Simple and Controllable Music Generation</td>\n",
       "      <td>https://arxiv.org/abs/2306.05284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Unverified</td>\n",
       "      <td>We tackle the task of conditional music genera...</td>\n",
       "      <td>2023-06-09 18:28:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             System      Domain                             Task  \\\n",
       "0            PaLM 2    Language               Language modelling   \n",
       "1             GPT-4  Multimodal               Language modelling   \n",
       "2           Phenaki      Vision                 Video generation   \n",
       "3    Minerva (540B)    Language  Quantitative Reasoning Problems   \n",
       "4       PaLM (540B)    Language               Language modelling   \n",
       "..              ...         ...                              ...   \n",
       "545          AR-LDM  Multimodal                    Text-to-image   \n",
       "546             NaN      Vision             Image classification   \n",
       "547         AltCLIP  Multimodal                              NaN   \n",
       "548         ALM 1.0    Language               Language modelling   \n",
       "549        MusicGen       Audio                 Audio generation   \n",
       "\n",
       "                                          Organization  \\\n",
       "0                                      Google Research   \n",
       "1                                               OpenAI   \n",
       "2    Google Brain, University College London, Unive...   \n",
       "3                                      Google Research   \n",
       "4                                      Google Research   \n",
       "..                                                 ...   \n",
       "545                                            Alibaba   \n",
       "546  University of Guelph,Canadian Institute for Ad...   \n",
       "547                                               BAAI   \n",
       "548                                               BAAI   \n",
       "549                                            Meta AI   \n",
       "\n",
       "                           Organization Categorization  \\\n",
       "0                                             Industry   \n",
       "1                                             Industry   \n",
       "2    Industry - Academia Collaboration (Industry le...   \n",
       "3                                             Industry   \n",
       "4                                             Industry   \n",
       "..                                                 ...   \n",
       "545  Industry - Academia Collaboration (Industry le...   \n",
       "546                  Industry - Academia Collaboration   \n",
       "547                                           Academia   \n",
       "548                                           Academia   \n",
       "549                                           Industry   \n",
       "\n",
       "                                               Authors Publication date  \\\n",
       "0    Andrew M. Dai, David R. So, Dmitry Lepikhin, J...       2023-05-10   \n",
       "1                                               OpenAI       2023-03-15   \n",
       "2    Ruben Villegas, Mohammad Babaeizadeh, Pieter-J...       2022-10-05   \n",
       "3    Aitor Lewkowycz, Anders Andreassen, David Doha...       2022-06-29   \n",
       "4    Aakanksha Chowdhery, Sharan Narang, Jacob Devl...       2022-04-04   \n",
       "..                                                 ...              ...   \n",
       "545  Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, We...       2022-11-20   \n",
       "546                 Terrance DeVries, Graham W. Taylor       2017-08-15   \n",
       "547  Zhongzhi Chen, Guang Liu, Bo-Wen Zhang, Fulong...       2022-11-12   \n",
       "548                                                NaN              NaN   \n",
       "549  Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, ...       2023-06-08   \n",
       "\n",
       "                                             Reference  \\\n",
       "0                              PaLM 2 Technical Report   \n",
       "1                               GPT-4 Technical Report   \n",
       "2    Phenaki: Variable Length Video Generation From...   \n",
       "3    Solving Quantitative Reasoning Problems with L...   \n",
       "4        PaLM: Scaling Language Modeling with Pathways   \n",
       "..                                                 ...   \n",
       "545  Synthesizing Coherent Story with Auto-Regressi...   \n",
       "546  Improved Regularization of Convolutional Neura...   \n",
       "547  AltCLIP: Altering the Language Encoder in CLIP...   \n",
       "548                                            ALM 1.0   \n",
       "549           Simple and Controllable Music Generation   \n",
       "\n",
       "                                                  Link  Citations  ...  \\\n",
       "0    https://ai.google/static/documents/palm2techre...        NaN  ...   \n",
       "1                     https://arxiv.org/abs/2303.08774        NaN  ...   \n",
       "2                     https://arxiv.org/abs/2210.02399        NaN  ...   \n",
       "3                     https://arxiv.org/abs/2206.14858        NaN  ...   \n",
       "4                     https://arxiv.org/abs/2204.02311      228.0  ...   \n",
       "..                                                 ...        ...  ...   \n",
       "545                   https://arxiv.org/abs/2211.10950        NaN  ...   \n",
       "546                   https://arxiv.org/abs/1708.04552     1450.0  ...   \n",
       "547                   https://arxiv.org/abs/2211.06679        NaN  ...   \n",
       "548  https://github.com/FlagAI-Open/FlagAI/blob/mas...        NaN  ...   \n",
       "549                   https://arxiv.org/abs/2306.05284        NaN  ...   \n",
       "\n",
       "    Training dataset size (GB) Approach  Training compute cost (2020 USD)  \\\n",
       "0                          NaN      NaN                               NaN   \n",
       "1                          NaN      NaN                               NaN   \n",
       "2                          NaN      NaN                               NaN   \n",
       "3                          NaN      NaN                     $3,267,257.75   \n",
       "4                          NaN      NaN                     $3,232,806.53   \n",
       "..                         ...      ...                               ...   \n",
       "545                        NaN      NaN                               NaN   \n",
       "546                        NaN      NaN                               NaN   \n",
       "547                        NaN      NaN                               NaN   \n",
       "548                        NaN      NaN                               NaN   \n",
       "549                        NaN      NaN                               NaN   \n",
       "\n",
       "                                    Compute cost notes  \\\n",
       "0    PaLM 2 was trained on TPU v4 according to the ...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "545                                                NaN   \n",
       "546           https://www.yuzeh.com/data/agz-cost.html   \n",
       "547                                                NaN   \n",
       "548                                                NaN   \n",
       "549                                                NaN   \n",
       "\n",
       "     Self-supervised training Architecture Compute Sponsor Categorization  \\\n",
       "0                         NaN          NaN                       Industry   \n",
       "1                         Yes          NaN                            NaN   \n",
       "2                         Yes          NaN                            NaN   \n",
       "3                         Yes          NaN                       Industry   \n",
       "4                         Yes          NaN                       Industry   \n",
       "..                        ...          ...                            ...   \n",
       "545                       NaN          NaN                            NaN   \n",
       "546                       NaN          NaN                       Industry   \n",
       "547                       NaN          NaN                            NaN   \n",
       "548                       NaN          NaN                            NaN   \n",
       "549                       NaN          NaN                       Industry   \n",
       "\n",
       "    Epistemic status                                           Abstract  \\\n",
       "0                NaN  We introduce PaLM 2, a new state-of-the-art la...   \n",
       "1                NaN                                                NaN   \n",
       "2                NaN                                                NaN   \n",
       "3                NaN  Language models have achieved remarkable perfo...   \n",
       "4                NaN  Large language models have been shown to achie...   \n",
       "..               ...                                                ...   \n",
       "545           Likely  Conditioned diffusion models have demonstrated...   \n",
       "546              NaN                                                NaN   \n",
       "547           Likely  In this work, we present a conceptually simple...   \n",
       "548      Speculative                                                NaN   \n",
       "549       Unverified  We tackle the task of conditional music genera...   \n",
       "\n",
       "           Last Modified  \n",
       "0    2023-06-06 18:47:36  \n",
       "1    2023-05-29 20:51:04  \n",
       "2    2023-05-29 20:51:04  \n",
       "3    2023-06-08 00:39:43  \n",
       "4    2023-05-29 20:51:04  \n",
       "..                   ...  \n",
       "545  2023-06-09 16:04:47  \n",
       "546  2023-06-09 16:00:52  \n",
       "547  2023-06-09 16:04:45  \n",
       "548  2023-06-09 16:06:43  \n",
       "549  2023-06-09 18:28:28  \n",
       "\n",
       "[550 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Task</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Organization Categorization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>...</th>\n",
       "      <th>Training dataset size (GB)</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Training compute cost (2020 USD)</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Self-supervised training</th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Compute Sponsor Categorization</th>\n",
       "      <th>Epistemic status</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PaLM 2</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Andrew M. Dai, David R. So, Dmitry Lepikhin, J...</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>PaLM 2 Technical Report</td>\n",
       "      <td>https://ai.google/static/documents/palm2techre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaLM 2 was trained on TPU v4 according to the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We introduce PaLM 2, a new state-of-the-art la...</td>\n",
       "      <td>2023-06-06 18:47:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Industry</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>https://arxiv.org/abs/2303.08774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Minerva (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Quantitative Reasoning Problems</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aitor Lewkowycz, Anders Andreassen, David Doha...</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>Solving Quantitative Reasoning Problems with L...</td>\n",
       "      <td>https://arxiv.org/abs/2206.14858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$3,267,257.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language models have achieved remarkable perfo...</td>\n",
       "      <td>2023-06-08 00:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaLM (540B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>Google Research</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Aakanksha Chowdhery, Sharan Narang, Jacob Devl...</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>PaLM: Scaling Language Modeling with Pathways</td>\n",
       "      <td>https://arxiv.org/abs/2204.02311</td>\n",
       "      <td>228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$3,232,806.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large language models have been shown to achie...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>DeepMind</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>Training Compute-Optimal Large Language Models</td>\n",
       "      <td>https://arxiv.org/abs/2203.15556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$753,491.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We investigate the optimal model size and numb...</td>\n",
       "      <td>2023-05-29 20:51:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Taiyi-Stable\\nDiffusion</td>\n",
       "      <td>Drawing</td>\n",
       "      <td>Text-to-image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/IDEA-CCNL/Taiyi-Stable-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 16:04:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>CogVideo</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>Video generation</td>\n",
       "      <td>Tsinghua University,BAAI</td>\n",
       "      <td>Academia</td>\n",
       "      <td>Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Li...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>CogVideo: Large-scale Pretraining for Text-to-...</td>\n",
       "      <td>https://arxiv.org/abs/2205.15868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely</td>\n",
       "      <td>Large-scale pretrained transformers have creat...</td>\n",
       "      <td>2023-06-09 15:44:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Zidong Taichu</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese Academy of Sciences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zidong Ancestral multi-modal large model</td>\n",
       "      <td>https://gitee.com/zidongtaichu/multi-modal-models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 15:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vision</td>\n",
       "      <td>Image classification</td>\n",
       "      <td>University of Guelph,Canadian Institute for Ad...</td>\n",
       "      <td>Industry - Academia Collaboration</td>\n",
       "      <td>Terrance DeVries, Graham W. Taylor</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>Improved Regularization of Convolutional Neura...</td>\n",
       "      <td>https://arxiv.org/abs/1708.04552</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.yuzeh.com/data/agz-cost.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 16:00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ALM 1.0</td>\n",
       "      <td>Language</td>\n",
       "      <td>Language modelling</td>\n",
       "      <td>BAAI</td>\n",
       "      <td>Academia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALM 1.0</td>\n",
       "      <td>https://github.com/FlagAI-Open/FlagAI/blob/mas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Speculative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-09 16:06:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System      Domain                             Task  \\\n",
       "0                     PaLM 2    Language               Language modelling   \n",
       "1                      GPT-4  Multimodal               Language modelling   \n",
       "3             Minerva (540B)    Language  Quantitative Reasoning Problems   \n",
       "4                PaLM (540B)    Language               Language modelling   \n",
       "6                 Chinchilla    Language               Language modelling   \n",
       "..                       ...         ...                              ...   \n",
       "542  Taiyi-Stable\\nDiffusion     Drawing                    Text-to-image   \n",
       "543                 CogVideo  Multimodal                 Video generation   \n",
       "544            Zidong Taichu  Multimodal                              NaN   \n",
       "546                      NaN      Vision             Image classification   \n",
       "548                  ALM 1.0    Language               Language modelling   \n",
       "\n",
       "                                          Organization  \\\n",
       "0                                      Google Research   \n",
       "1                                               OpenAI   \n",
       "3                                      Google Research   \n",
       "4                                      Google Research   \n",
       "6                                             DeepMind   \n",
       "..                                                 ...   \n",
       "542                                                NaN   \n",
       "543                           Tsinghua University,BAAI   \n",
       "544                        Chinese Academy of Sciences   \n",
       "546  University of Guelph,Canadian Institute for Ad...   \n",
       "548                                               BAAI   \n",
       "\n",
       "           Organization Categorization  \\\n",
       "0                             Industry   \n",
       "1                             Industry   \n",
       "3                             Industry   \n",
       "4                             Industry   \n",
       "6                             Industry   \n",
       "..                                 ...   \n",
       "542                                NaN   \n",
       "543                           Academia   \n",
       "544                                NaN   \n",
       "546  Industry - Academia Collaboration   \n",
       "548                           Academia   \n",
       "\n",
       "                                               Authors Publication date  \\\n",
       "0    Andrew M. Dai, David R. So, Dmitry Lepikhin, J...       2023-05-10   \n",
       "1                                               OpenAI       2023-03-15   \n",
       "3    Aitor Lewkowycz, Anders Andreassen, David Doha...       2022-06-29   \n",
       "4    Aakanksha Chowdhery, Sharan Narang, Jacob Devl...       2022-04-04   \n",
       "6    Jordan Hoffmann, Sebastian Borgeaud, Arthur Me...       2022-03-29   \n",
       "..                                                 ...              ...   \n",
       "542                                                NaN       2022-10-31   \n",
       "543  Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Li...       2022-05-29   \n",
       "544                                                NaN              NaN   \n",
       "546                 Terrance DeVries, Graham W. Taylor       2017-08-15   \n",
       "548                                                NaN              NaN   \n",
       "\n",
       "                                             Reference  \\\n",
       "0                              PaLM 2 Technical Report   \n",
       "1                               GPT-4 Technical Report   \n",
       "3    Solving Quantitative Reasoning Problems with L...   \n",
       "4        PaLM: Scaling Language Modeling with Pathways   \n",
       "6       Training Compute-Optimal Large Language Models   \n",
       "..                                                 ...   \n",
       "542                                                NaN   \n",
       "543  CogVideo: Large-scale Pretraining for Text-to-...   \n",
       "544           Zidong Ancestral multi-modal large model   \n",
       "546  Improved Regularization of Convolutional Neura...   \n",
       "548                                            ALM 1.0   \n",
       "\n",
       "                                                  Link  Citations  ...  \\\n",
       "0    https://ai.google/static/documents/palm2techre...        NaN  ...   \n",
       "1                     https://arxiv.org/abs/2303.08774        NaN  ...   \n",
       "3                     https://arxiv.org/abs/2206.14858        NaN  ...   \n",
       "4                     https://arxiv.org/abs/2204.02311      228.0  ...   \n",
       "6                     https://arxiv.org/abs/2203.15556        NaN  ...   \n",
       "..                                                 ...        ...  ...   \n",
       "542  https://huggingface.co/IDEA-CCNL/Taiyi-Stable-...        NaN  ...   \n",
       "543                   https://arxiv.org/abs/2205.15868        NaN  ...   \n",
       "544  https://gitee.com/zidongtaichu/multi-modal-models        NaN  ...   \n",
       "546                   https://arxiv.org/abs/1708.04552     1450.0  ...   \n",
       "548  https://github.com/FlagAI-Open/FlagAI/blob/mas...        NaN  ...   \n",
       "\n",
       "    Training dataset size (GB) Approach  Training compute cost (2020 USD)  \\\n",
       "0                          NaN      NaN                               NaN   \n",
       "1                          NaN      NaN                               NaN   \n",
       "3                          NaN      NaN                     $3,267,257.75   \n",
       "4                          NaN      NaN                     $3,232,806.53   \n",
       "6                          NaN      NaN                       $753,491.58   \n",
       "..                         ...      ...                               ...   \n",
       "542                        NaN      NaN                               NaN   \n",
       "543                        NaN      NaN                               NaN   \n",
       "544                        NaN      NaN                               NaN   \n",
       "546                        NaN      NaN                               NaN   \n",
       "548                        NaN      NaN                               NaN   \n",
       "\n",
       "                                    Compute cost notes  \\\n",
       "0    PaLM 2 was trained on TPU v4 according to the ...   \n",
       "1                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "6                                                  NaN   \n",
       "..                                                 ...   \n",
       "542                                                NaN   \n",
       "543                                                NaN   \n",
       "544                                                NaN   \n",
       "546           https://www.yuzeh.com/data/agz-cost.html   \n",
       "548                                                NaN   \n",
       "\n",
       "     Self-supervised training Architecture Compute Sponsor Categorization  \\\n",
       "0                         NaN          NaN                       Industry   \n",
       "1                         Yes          NaN                            NaN   \n",
       "3                         Yes          NaN                       Industry   \n",
       "4                         Yes          NaN                       Industry   \n",
       "6                         Yes          NaN                       Industry   \n",
       "..                        ...          ...                            ...   \n",
       "542                       NaN          NaN                            NaN   \n",
       "543                       NaN          NaN                            NaN   \n",
       "544                       NaN          NaN                            NaN   \n",
       "546                       NaN          NaN                       Industry   \n",
       "548                       NaN          NaN                            NaN   \n",
       "\n",
       "    Epistemic status                                           Abstract  \\\n",
       "0                NaN  We introduce PaLM 2, a new state-of-the-art la...   \n",
       "1                NaN                                                NaN   \n",
       "3                NaN  Language models have achieved remarkable perfo...   \n",
       "4                NaN  Large language models have been shown to achie...   \n",
       "6                NaN  We investigate the optimal model size and numb...   \n",
       "..               ...                                                ...   \n",
       "542           Likely                                                NaN   \n",
       "543           Likely  Large-scale pretrained transformers have creat...   \n",
       "544           Likely                                                NaN   \n",
       "546              NaN                                                NaN   \n",
       "548      Speculative                                                NaN   \n",
       "\n",
       "           Last Modified  \n",
       "0    2023-06-06 18:47:36  \n",
       "1    2023-05-29 20:51:04  \n",
       "3    2023-06-08 00:39:43  \n",
       "4    2023-05-29 20:51:04  \n",
       "6    2023-05-29 20:51:04  \n",
       "..                   ...  \n",
       "542  2023-06-09 16:04:42  \n",
       "543  2023-06-09 15:44:54  \n",
       "544  2023-06-09 15:44:36  \n",
       "546  2023-06-09 16:00:52  \n",
       "548  2023-06-09 16:06:43  \n",
       "\n",
       "[370 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notable_df = df.dropna(subset=['Inclusion criteria'])\n",
    "notable_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of notable ML systems for each Organization since 2010.\n",
    "organization_system_count = defaultdict(int)\n",
    "for i, row in notable_df.iterrows():\n",
    "    pub_date = row['Publication date']\n",
    "    if type(pub_date) == str and int(pub_date[:4]) >= 2010 and row['Organization Categorization'] == 'Industry':\n",
    "        org = row['Organization']\n",
    "        organization_system_count[org] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google: 20 systems\n",
      "DeepMind: 16 systems\n",
      "OpenAI: 12 systems\n",
      "Google Research: 7 systems\n",
      "Google Brain: 7 systems\n",
      "Google DeepMind: 7 systems\n",
      "Microsoft Research: 5 systems\n",
      "Meta AI: 4 systems\n",
      "Facebook AI Research: 4 systems\n",
      "Facebook AI research: 4 systems\n",
      "MetaAI: 3 systems\n",
      "Microsoft: 3 systems\n",
      "Alibaba Group: 2 systems\n",
      "Facebook: 2 systems\n",
      "Facebook AI: 2 systems\n",
      "Google Inc.: 2 systems\n",
      "Amazon: 1 systems\n",
      "Stability AI, Runway: 1 systems\n",
      "Google AI, Brain team: 1 systems\n",
      "Microsoft Research,Peking University: 1 systems\n",
      "Open AI: 1 systems\n",
      "Microsoft Bing: 1 systems\n",
      "Google Research, Brain Team: 1 systems\n",
      "Google Research,Brain Team: 1 systems\n",
      "Google AI: 1 systems\n",
      "AllenAI, University of Washington: 1 systems\n",
      "Google Brain,Google Research: 1 systems\n",
      "Twitter: 1 systems\n",
      "Megvii Inc: 1 systems\n",
      "Nvidia: 1 systems\n",
      "Salesforce: 1 systems\n",
      "Baidu Research- Silicon Valley AI Lab: 1 systems\n",
      "Netflix: 1 systems\n",
      "Xerox Research Centre Europe (XRCE): 1 systems\n",
      "Google Inc: 1 systems\n",
      "NVIDIA: 1 systems\n",
      "Baidu: 1 systems\n"
     ]
    }
   ],
   "source": [
    "# Print organization and its system count, in descending order of count\n",
    "for org, count in sorted(organization_system_count.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{org}: {count} systems\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Industry:\n",
    "1. Google: 42\n",
    "  - Google: 20\n",
    "  - Google Research: 7\n",
    "  - Google Brain: 7\n",
    "  - Google Inc.: 2\n",
    "  - Google AI, Brain team: 1\n",
    "  - Google Research, Brain Team: 1\n",
    "  - Google Research,Brain Team: 1\n",
    "  - Google AI: 1\n",
    "  - Google Brain,Google Research: 1\n",
    "  - Google Inc: 1\n",
    "2. DeepMind: 23\n",
    "  - DeepMind: 16\n",
    "  - Google DeepMind: 7\n",
    "3. Meta: 20\n",
    "  - Meta AI: 4\n",
    "  - MetaAI: 4\n",
    "  - Facebook AI Research: 4\n",
    "  - Facebook AI research: 4\n",
    "  - Facebook: 2\n",
    "  - Facebook AI 2\n",
    "4. OpenAI: 13\n",
    "   1. OpenAI: 12\n",
    "   2. Open AI: 1\n",
    "5. Microsoft: 10\n",
    "   - Microsoft Research: 5\n",
    "   - Microsoft: 3\n",
    "   - Microsoft Research,Peking University: 1\n",
    "   - Microsoft Bing: 1\n",
    "6. Alibaba: 2\n",
    "  - Alibaba Group: 2\n",
    "6. NVIDIA: 2\n",
    "  - Nvidia: 1\n",
    "  - NVIDIA: 1\n",
    "6. Baidu: 2\n",
    "  - Baidu Research- Silicon Valley AI Lab: 1\n",
    "  - Baidu: 1\n",
    "7. Amazon: 1\n",
    "  - Amazon: 1\n",
    "7. Stability: 1\n",
    "  - Stability AI, Runway: 1\n",
    "7. Runway: 1\n",
    "  - Stability AI, Runway: 1\n",
    "7. Twitter: 1\n",
    "7. Megvii: \n",
    "  - Megvii Inc: 1\n",
    "7. Salesforce: 1\n",
    "  - Salesforce: 1\n",
    "7. Netflix: 1\n",
    "  - Netflix: 1\n",
    "7. Xerox: 1\n",
    "  - Xerox Research Centre Europe (XRCE): 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_ids = [\n",
    "    # 'https://openalex.org/C154945302',  # Artificial intelligence\n",
    "    'https://openalex.org/C119857082',  # Machine learning\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openalex.org/C119857082'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_query = \"|\".join(concept_ids)\n",
    "concept_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_institutions = merge_pages(\n",
    "    Institutions() \\\n",
    "        .filter(concepts={\"id\": concept_query}) \\\n",
    "        .filter(type=\"company\") \\\n",
    "        .sort(works_count=\"desc\") \\\n",
    "        .paginate(per_page=200, n_max=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 2023, 'works_count': 432, 'cited_by_count': 254671},\n",
       " {'year': 2022, 'works_count': 1238, 'cited_by_count': 594200},\n",
       " {'year': 2021, 'works_count': 3008, 'cited_by_count': 1006528},\n",
       " {'year': 2020, 'works_count': 3192, 'cited_by_count': 827724},\n",
       " {'year': 2019, 'works_count': 2818, 'cited_by_count': 557240},\n",
       " {'year': 2018, 'works_count': 2073, 'cited_by_count': 326302},\n",
       " {'year': 2017, 'works_count': 1536, 'cited_by_count': 176882},\n",
       " {'year': 2016, 'works_count': 1265, 'cited_by_count': 121938},\n",
       " {'year': 2015, 'works_count': 1105, 'cited_by_count': 87186},\n",
       " {'year': 2014, 'works_count': 892, 'cited_by_count': 61367},\n",
       " {'year': 2013, 'works_count': 833, 'cited_by_count': 45477},\n",
       " {'year': 2012, 'works_count': 691, 'cited_by_count': 33851}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_institutions[1]['counts_by_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_cited_by_count = defaultdict(int)\n",
    "ins_works_count = defaultdict(int)\n",
    "for ins_obj in top_institutions:\n",
    "    counts_by_year = ins_obj['counts_by_year']\n",
    "    for year_counts in counts_by_year:\n",
    "        if year_counts['year'] >= 2010:\n",
    "            ins_cited_by_count[ins_obj['id']] += year_counts['cited_by_count']\n",
    "            ins_works_count[ins_obj['id']] += year_counts['works_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google (United States): 19083 works\n",
      "Microsoft (United States): 15487 works\n",
      "Microsoft Research (United Kingdom): 7212 works\n",
      "Huawei Technologies (China): 7017 works\n",
      "Amazon (United States): 5459 works\n",
      "Tencent (China): 4535 works\n",
      "Meta (Israel): 4244 works\n",
      "Tata Consultancy Services (India): 3574 works\n",
      "China Mobile (China): 3467 works\n",
      "Alibaba Group (China): 3428 works\n",
      "Adobe Systems (United States): 3415 works\n",
      "Microsoft Research Asia (China): 3374 works\n",
      "Baidu (China): 2823 works\n",
      "Decision Systems (United States): 2765 works\n",
      "Aditya Birla (India): 2529 works\n",
      "Management Sciences (United States): 2309 works\n",
      "Meta (United States): 2173 works\n",
      "Amazon (Germany): 2104 works\n",
      "Aselsan (Turkey): 1872 works\n",
      "Nvidia (United States): 1782 works\n",
      "Alibaba Group (United States): 1675 works\n"
     ]
    }
   ],
   "source": [
    "for i, (ins, works_count) in enumerate(sorted(ins_works_count.items(), key=lambda x: x[1], reverse=True)):\n",
    "    if i > 20:\n",
    "        break\n",
    "    print(f\"{Institutions()[ins]['display_name']}: {works_count} works\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
